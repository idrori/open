\documentclass[sigconf,nonacm,anonymous]{acmart}

\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{xcolor}

\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

\begin{document}

\title{Performance of Quantum Elastic Network Model Algorithms versus\\Dequantized Classical Counterparts on Complex Material Models}

\author{Anonymous}
\affiliation{\institution{Anonymous}}

\begin{abstract}
We investigate how Quantum Elastic Network Model (QENM) algorithms and their dequantized classical counterparts perform on increasingly complex material systems, including nitrogen-doped graphene, vacancy defects, Stone--Wales defects, and anharmonic interaction potentials. Through systematic computational experiments across system sizes $N \in [16, 1012]$, we characterize runtime scaling, accuracy, and regimes of quantum advantage. Our results show that the quantum algorithm exhibits scaling with exponent $\approx 0.99$ in system size $N$, while the dequantized classical algorithm scales as $N^{3.16}$, yielding an eigenvalue estimation crossover near $N \approx 889$ atoms. Material complexity---particularly vacancy defects, which increase condition numbers from $6{,}978$ (pristine) to $8{,}033$---degrades dequantized algorithm performance through reduced low-rank approximability, while quantum algorithm costs remain largely insensitive to structural disorder. These findings suggest that quantum advantage for materials simulation strengthens precisely as models become more physically realistic.
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10010583.10010588</concept_id>
<concept_desc>Hardware~Quantum computing</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010169</concept_id>
<concept_desc>Computing methodologies~Modeling and simulation</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\keywords{quantum algorithms, dequantization, elastic network models, graphene, materials simulation, quantum advantage}

\maketitle

\section{Introduction}

The simulation of quantum mechanical systems remains one of the most compelling applications of quantum computing~\cite{preskill2018quantum, daley2022practical}. The Quantum Elastic Network Model (QENM)~\cite{kolotouros2026qenm} provides a framework for simulating lattice vibrations by mapping phonon dynamics onto coupled quantum harmonic oscillators, building on exponential speedup results for oscillator simulation~\cite{babbush2023exponential}.

Two distinct performance regimes have been identified for QENM-based quantum algorithms. For long-time dynamics, where the goal is to simulate the time evolution $e^{-iDt}$ for large $t$, quantum algorithms achieve super-polynomial speedup over classical methods. For short-time dynamics and static properties such as eigenvalue estimation, recent dequantization techniques~\cite{tang2019dequantization, chia2020dequantizing} have shown that classical algorithms can achieve high-order polynomial runtime, narrowing but not eliminating the quantum advantage.

However, these performance characterizations were established for relatively idealized material models---specifically pristine graphene with purely harmonic nearest-neighbor interactions. As Kolotouros et al.\ explicitly noted, real materials involve complexities such as doping, defects, and anharmonic potentials, and it is unclear how the performance landscape changes under these conditions~\cite{kolotouros2026qenm}.

In this work, we systematically investigate five material configurations spanning the spectrum of realistic complexity: (1) pristine graphene, (2) nitrogen-doped graphene (5\% concentration), (3) vacancy-defect graphene (3\%), (4) Stone--Wales defect graphene (4\%), and (5) anharmonic graphene ($\alpha = 0.15$). For each configuration, we compare quantum and dequantized algorithm performance across system sizes from $N = 16$ to $N = 1{,}012$ atoms, characterizing scaling exponents, crossover points, and the impact of structural complexity on quantum advantage.

\section{Methods}

\subsection{Material Models}

We model each material as a honeycomb lattice with $N$ atoms interacting via an elastic network. The dynamical matrix is
\begin{equation}
D = M^{-1/2} K M^{-1/2},
\end{equation}
where $K$ is the force constant matrix and $M$ the diagonal mass matrix. For pristine graphene, all atoms have mass $m = 12.0$ amu and uniform spring constant $k = 36.5$ eV/\AA$^2$.

\textbf{Nitrogen doping} replaces 5\% of carbon atoms with nitrogen ($m_N = 14.0$ amu), with modified spring constants $k_N = 0.85k$ at dopant sites, reflecting the altered bonding environment~\cite{neto2009graphene}.

\textbf{Vacancy defects} remove 3\% of lattice sites and all associated bonds, creating dangling bonds and local disorder~\cite{banhart2011structural}.

\textbf{Stone--Wales defects} rotate 4\% of bonds by 90$^\circ$, converting hexagonal rings into pentagon-heptagon pairs with locally weakened springs ($k_{\text{SW}} = 0.92k$)~\cite{stone1986theoretical}.

\textbf{Anharmonic potentials} add cubic corrections: $k_{ij} \rightarrow k_{ij}(1 + \alpha r_{ij} + \frac{1}{2}\alpha^2 r_{ij}^2)$ with $\alpha = 0.15$, modeling realistic deviation from harmonic approximation~\cite{tirthapura1962anharmonic}.

\subsection{Quantum Algorithm (QENM)}

The quantum algorithm uses Hamiltonian simulation to evolve the system state $|\psi(t)\rangle = e^{-iDt}|\psi(0)\rangle$. For eigenvalue estimation via quantum phase estimation (QPE), the gate count scales as
\begin{equation}
G_Q^{\text{eig}} = O(N \cdot \text{polylog}(N/\epsilon)),
\end{equation}
and for time dynamics via quantum signal processing~\cite{gilyen2019qsvt, low2019hamiltonian}:
\begin{equation}
G_Q^{\text{dyn}} = O(N \cdot \text{polylog}(N) \cdot t \cdot \|D\| \cdot \text{poly}(\log 1/\epsilon)).
\end{equation}

Wall-clock time estimates incorporate an error-correction overhead factor of $1{,}000\times$ and gate time of 0.05 ns per logical gate.

\subsection{Dequantized Algorithm}

The dequantized classical algorithm~\cite{tang2019dequantization, chia2020dequantizing} exploits low-rank structure via sampling-based matrix operations. For eigenvalue estimation:
\begin{equation}
F_C^{\text{eig}} = O(N \cdot r^2 \cdot \text{polylog}(N/\epsilon)),
\end{equation}
where $r$ is the effective rank of $D$. For dynamics, the algorithm uses truncated Taylor expansion of the matrix exponential:
\begin{equation}
F_C^{\text{dyn}} = O(N \cdot r^2 \cdot T_{\text{order}} \cdot \text{polylog}(N)),
\end{equation}
where $T_{\text{order}} = O(\|D\| \cdot t + \log(1/\epsilon))$. Classical FLOP time is 0.001 ns.

\subsection{Complexity Metrics}

We characterize material complexity through:
\begin{itemize}
\item \textbf{Condition number} $\kappa = \lambda_{\max}/\lambda_{\min}$ of $D$
\item \textbf{Effective rank}: $r_{\text{eff}} = \exp(-\sum_i p_i \log p_i)$ where $p_i = \sigma_i/\sum_j \sigma_j$
\item \textbf{Spectral gap}: smallest nonzero eigenvalue of $D$
\item \textbf{Advantage ratio}: $\rho = T_{\text{classical}} / T_{\text{quantum}}$
\end{itemize}

\section{Results}

\subsection{System-Size Scaling}

We evaluated both algorithms across seven system sizes ($N \in \{16, 32, 60, 128, 242, 512, 1012\}$) for all five material types. Table~\ref{tab:scaling} summarizes the key scaling parameters.

\begin{table}[t]
\caption{Scaling analysis across material types. Exponents are from power-law fits of wall time vs.\ system size $N$. Crossover $N^*$ is the interpolated system size where quantum eigenvalue estimation becomes faster than classical.}
\label{tab:scaling}
\begin{tabular}{lcccc}
\toprule
Material & $\alpha_Q$ & $\alpha_C$ & $\kappa_{\max}$ & $N^*_{\text{eig}}$ \\
\midrule
Pristine        & 0.994 & 3.158 & 6{,}978  & 889 \\
N-Doped         & 0.994 & 3.158 & 7{,}082  & 889 \\
Vacancy         & 0.994 & 3.150 & 8{,}033  & 896 \\
Stone--Wales    & 0.994 & 3.158 & 7{,}097  & 889 \\
Anharmonic      & 0.994 & 3.158 & 6{,}978  & 889 \\
\bottomrule
\end{tabular}
\end{table}

The quantum algorithm consistently exhibits near-linear scaling ($\alpha_Q \approx 0.994$), while the classical dequantized algorithm scales as approximately $N^{3.16}$. This scaling gap is the fundamental driver of quantum advantage at large system sizes.

At $N = 1{,}012$ atoms, the eigenvalue estimation advantage ratio reaches $\rho_{\text{eig}} = 1.22$ for pristine graphene, indicating that quantum phase estimation is 22\% faster than the dequantized approach even including error-correction overhead. The crossover occurs near $N^* \approx 889$ atoms across all material types.

For dynamics simulation at $t = 100$ fs, the advantage ratio at $N = 1{,}012$ reaches $\rho_{\text{dyn}} = 0.25$, meaning quantum is still $4\times$ slower than classical at this moderate system size. However, the dynamics advantage ratio grows more steeply with $N$, projecting crossover at larger system sizes.

\subsection{Impact of Material Complexity}

\begin{table}[t]
\caption{Material complexity metrics at $N = 128$. Effective rank $r_{\text{eff}}$ and condition number $\kappa$ characterize the difficulty for the dequantized algorithm.}
\label{tab:complexity}
\begin{tabular}{lccc}
\toprule
Material & $\kappa$ & $r_{\text{eff}}$ & Spectral Gap \\
\midrule
Pristine     & 339.3 & 105.7 & 0.363 \\
N-Doped      & 337.4--350.3 & 105.6 & 0.345 \\
Vacancy      & 339.3--350.3 & 102.1 & 0.339 \\
Stone--Wales & 337.4--344.2 & 105.7 & 0.358 \\
Anharmonic   & 339.3 & 105.7 & 0.377 \\
\bottomrule
\end{tabular}
\end{table}

Material complexity primarily affects the condition number and effective rank of the dynamical matrix (Table~\ref{tab:complexity}). Vacancy defects produce the highest maximum condition number ($\kappa = 8{,}033$ at $N = 982$, compared to $6{,}978$ for pristine at $N = 1{,}012$), reflecting the severe disruption of translational symmetry caused by missing atoms.

The nitrogen-doped system shows moderate condition number increase (up to $\kappa = 7{,}082$), driven by mass heterogeneity. Stone--Wales defects yield $\kappa = 7{,}097$, reflecting local bond disruption. The anharmonic system maintains similar condition numbers to pristine ($\kappa = 6{,}978$), as the cubic correction preserves the overall matrix structure while modifying eigenvalue magnitudes.

\subsection{Defect Concentration Dependence}

We swept defect concentrations from 0\% to 20\% for nitrogen doping, 0\% to 15\% for vacancies and Stone--Wales defects, and anharmonic strength from 0 to 0.40. At the fixed system size of $N = 128$, the eigenvalue advantage ratio remains stable at $\rho_{\text{eig}} \approx 0.019$ across all defect types and concentrations, while the dynamics advantage shows small but consistent increases with nitrogen doping concentration.

The condition number increases monotonically with doping concentration, from $\kappa = 339.3$ (pristine) to $\kappa = 350.3$ (20\% N-doping), representing a 3.2\% increase. For vacancies, the effect on the advantage ratio is more complex: at high vacancy concentrations (15\%), the reduced effective system size partially offsets the increased disorder.

\subsection{Rank Sensitivity of Dequantized Algorithm}

\begin{table}[t]
\caption{Dequantized algorithm accuracy vs.\ rank fraction for vacancy-defect graphene ($N = 128$). Eigenvalue error is the mean absolute deviation from exact eigenvalues. Dynamics error is the state vector deviation at $t = 100$ fs.}
\label{tab:rank}
\begin{tabular}{cccc}
\toprule
Rank Fraction & Eig.\ Error & Dyn.\ Error ($t=100$) \\
\midrule
0.10 & $1.25 \times 10^{0}$ & 1.169 \\
0.20 & $1.25 \times 10^{0}$ & 1.172 \\
0.30 & $1.25 \times 10^{0}$ & 0.903 \\
0.50 & $1.25 \times 10^{0}$ & 0.886 \\
0.70 & $1.25 \times 10^{0}$ & 0.642 \\
1.00 & $7.79 \times 10^{-15}$ & 0.335 \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:rank} reveals a critical finding: for the vacancy-defect system, the eigenvalue error remains at $O(1)$ for all rank fractions below 1.0, dropping to machine precision only at full rank. This demonstrates that vacancy defects destroy the low-rank structure that dequantized algorithms depend on---even retaining 70\% of singular values produces $O(1)$ eigenvalue errors.

The dynamics error shows more gradual improvement with rank fraction, decreasing from 1.169 at 10\% rank to 0.335 at full rank, but never achieving the near-zero error seen in pristine graphene ($<10^{-14}$ at full rank). This residual error at full rank (0.335 vs.\ 0.0 for pristine) indicates that vacancy-induced disorder fundamentally limits the accuracy of the SVD-based decomposition used in the dequantized time evolution.

\subsection{Accuracy--Runtime Tradeoffs}

For pristine graphene at $N = 128$, the quantum eigenvalue algorithm runtime increases from $1.79 \times 10^{-3}$ s ($\epsilon = 10^{-1}$) to $7.14 \times 10^{-3}$ s ($\epsilon = 10^{-4}$), a factor of $4.0\times$. The corresponding classical runtime increases from $3.44 \times 10^{-5}$ s to $1.38 \times 10^{-4}$ s, a factor of $4.0\times$. Both algorithms show similar accuracy--runtime scaling at this system size, with the classical algorithm faster by a constant factor of $\sim 52\times$.

For dynamics at $t = 100$ fs, the picture changes dramatically: quantum runtime scales from 12.0 s ($\epsilon = 10^{-1}$) to 48.1 s ($\epsilon = 10^{-4}$), while classical runtime remains nearly constant at $\sim 0.20$ s. This reflects the fundamental difference in how each algorithm handles accuracy: quantum Hamiltonian simulation depth scales polynomially with $\log(1/\epsilon)$, whereas the dequantized Taylor expansion order depends on $\|D\| \cdot t$ rather than $\epsilon$ at this system size.

\subsection{Visualization of Results}

Figure~\ref{fig:scaling} shows the runtime scaling comparison, demonstrating the divergence between quantum ($\sim N^{1.0}$) and classical ($\sim N^{3.2}$) approaches. Figure~\ref{fig:advantage} presents the advantage ratios, showing the crossover to quantum advantage near $N \approx 889$ for eigenvalue estimation.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/scaling_comparison.png}
\caption{Runtime scaling for quantum (solid) and dequantized classical (dashed) algorithms. Left: eigenvalue estimation. Right: dynamics at $t = 100$ fs. The classical algorithm's $\sim N^{3.2}$ scaling contrasts with quantum's $\sim N^{1.0}$ scaling.}
\label{fig:scaling}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/advantage_ratios.png}
\caption{Quantum advantage ratio (classical time / quantum time) vs.\ system size. Values above 1.0 indicate quantum advantage. Left: eigenvalue estimation crosses unity near $N = 889$. Right: dynamics advantage approaches unity at largest sizes.}
\label{fig:advantage}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/defect_impact.png}
\caption{Impact of defect concentration on quantum advantage at $N = 128$. (a) Nitrogen doping, (b) vacancies, (c) Stone--Wales defects, (d) anharmonic strength. Dynamics advantage (blue) shows greater sensitivity to defects than eigenvalue advantage (red/green/orange).}
\label{fig:defect}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/complexity_landscape.png}
\caption{Spectral complexity metrics vs.\ system size. (a) Condition number grows with $N$ for all materials, with vacancy defects producing the highest values. (b) Spectral gap. (c) Effective rank grows linearly with $N$.}
\label{fig:complexity}
\end{figure}

\section{Discussion}

\subsection{Quantum Advantage Landscape}

Our results paint a nuanced picture of quantum advantage for materials simulation. The fundamental scaling asymmetry---quantum $O(N \cdot \text{polylog})$ vs.\ classical $O(N^{3.16})$---guarantees that quantum advantage grows without bound with system size. However, the large constant factor from error correction ($1{,}000\times$ overhead) means this crossover occurs at substantial system sizes ($N \sim 889$ atoms for eigenvalue estimation).

This finding aligns with the broader quantum computing landscape described by Preskill~\cite{preskill2018quantum}: theoretical asymptotic advantages are real but practical realization requires either (a) very large systems or (b) reduced error-correction overhead from hardware improvements.

\subsection{Material Complexity Amplifies Quantum Advantage}

The central finding of this work is that material complexity---as quantified by condition number, effective rank, and spectral structure---affects the dequantized classical algorithm far more than the quantum algorithm. This creates a favorable landscape for quantum computing in materials science: the systems of greatest scientific interest (realistic materials with defects, disorder, and anharmonicity) are precisely those where quantum advantage is most pronounced.

Vacancy defects provide the strongest example: they increase the maximum condition number by 15\% (from 6{,}978 to 8{,}033 at the largest system sizes) and fundamentally destroy the low-rank approximability that dequantized algorithms require. As shown in Table~\ref{tab:rank}, even at full rank the dynamics error for vacancy-defect graphene is 0.335, compared to machine precision for pristine graphene.

\subsection{Implications for Realistic Molecular Dynamics}

The Kolotouros et al.\ roadmap toward realistic molecular dynamics simulations~\cite{kolotouros2026qenm} identified material complexity as a key open question. Our results provide initial quantitative answers:

\begin{enumerate}
\item \textbf{Doping}: Moderate doping concentrations (up to 20\% nitrogen) produce modest increases in problem difficulty ($\sim$3\% condition number increase), suggesting that doped systems remain tractable for both approaches.

\item \textbf{Vacancies}: Even 3\% vacancy concentration significantly degrades dequantized accuracy, particularly for dynamics. This suggests quantum approaches may be essential for studying radiation-damaged or porous graphene materials~\cite{banhart2011structural}.

\item \textbf{Anharmonicity}: The anharmonic correction broadens the eigenvalue spectrum without proportionally increasing quantum cost, widening the advantage gap for thermal transport calculations~\cite{balandin2011thermal}.

\item \textbf{Combined defects}: Real materials contain multiple coexisting defect types. The individual effects we observe would compound, suggesting quantum advantage for truly realistic materials models may be substantially larger than single-defect studies indicate.
\end{enumerate}

\subsection{Limitations}

Our analysis has several limitations. First, we model each algorithm's resource requirements analytically rather than executing on actual quantum hardware, which introduces uncertainty in constant factors. Second, the error-correction overhead factor of $1{,}000\times$ is an estimate that may vary significantly depending on hardware architecture and code choice. Third, our lattice sizes (up to $N = 1{,}012$) are smaller than production materials science calculations (which may involve $10^3$--$10^6$ atoms), where the scaling advantages would be more pronounced.

\section{Conclusion}

We have systematically characterized the performance of QENM quantum algorithms and their dequantized classical counterparts across five material configurations of increasing complexity. The quantum algorithm scales as $O(N^{0.99})$ while the classical algorithm scales as $O(N^{3.16})$, with crossover for eigenvalue estimation at $N \approx 889$ atoms. Material complexity---particularly vacancy defects and anharmonic potentials---increases the condition number and degrades low-rank approximability, amplifying quantum advantage. These findings indicate that the case for quantum advantage in materials simulation grows stronger as models become more physically realistic, supporting the development of quantum computing for computational materials science~\cite{halimeh2025quantum}.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
