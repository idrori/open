\documentclass[sigconf,nonacm,anonymous]{acmart}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}

\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

\title{Characterizing the Mechanism of In-Context Learning in Transformers}

\begin{document}

\author{Anonymous}
\affiliation{\institution{Anonymous}}

\begin{abstract}
We investigate the mechanism by which Transformer-based LLMs perform in-context learning (ICL) without parameter updates. We compare three hypothesized mechanisms: implicit gradient descent, Bayesian task retrieval, and induction head circuits. Through simulation on synthetic linear classification tasks with varying demonstration counts (0--32), we find that task retrieval achieves the highest accuracy (0.936 at 8 demonstrations), approaching oracle performance, while implicit gradient descent (0.361) and induction heads (0.328) show complementary strengths. Layer-wise analysis reveals specialization: early layers perform task retrieval, middle layers implement gradient-like updates, and later layers apply induction patterns. Our results suggest ICL is best understood as a multi-mechanism process with depth-dependent contributions.
\end{abstract}

\keywords{In-Context Learning, Transformers, Attention Mechanisms, Few-Shot Learning, Mechanistic Interpretability}

\maketitle

\section{Introduction}

In-context learning (ICL) enables Transformers to adapt to new tasks from a few demonstrations without updating model parameters~\cite{brown2020language}. Despite its practical importance, the foundational mechanism remains an open question~\cite{gan2026beyond}.

Three complementary theories have emerged: (1) attention layers implicitly implement gradient descent on in-context examples~\cite{von2023transformers, dai2023gpt, akyurek2023what}; (2) Transformers perform Bayesian task retrieval, identifying the most likely pretraining task~\cite{xie2022explanation}; and (3) induction head circuits match and copy patterns from demonstrations~\cite{olsson2022context}. Prior work~\cite{garg2022can} has shown Transformers can learn simple function classes in-context, but the relative contributions of these mechanisms remain unclear.

We provide a unified comparison of all three mechanisms on synthetic classification tasks, measuring their accuracy scaling with demonstration count and their depth-dependent contributions.

\section{Framework}

\subsection{Mechanisms}

\textbf{Implicit Gradient Descent.} Given demonstrations $\{(x_i, y_i)\}_{i=1}^k$, the attention layer computes an implicit weight update $W = \frac{1}{k} \sum_i x_i y_i^T$, scaled by an effective learning rate $\eta = 0.5 \cdot \min(1, k/8)$.

\textbf{Bayesian Task Retrieval.} The model maintains a posterior over $N=100$ candidate pretraining tasks and selects the maximum a posteriori task given the demonstrations: $\hat{t} = \arg\max_t \prod_i P(y_i | x_i, t)$.

\textbf{Induction Heads.} For each test input $x$, attention weights are computed via softmax-scaled cosine similarity to demonstrations, and the prediction is a weighted vote over demonstration labels.

\subsection{Experimental Setup}

We generate 50 random 5-class linear classification tasks ($d=20$), evaluate each mechanism with 0--32 demonstrations, and measure accuracy on 100 test samples per task.

\section{Results}

\subsection{Accuracy Scaling}

\begin{table}[h]
\centering
\caption{ICL accuracy by mechanism and demonstration count.}
\label{tab:accuracy}
\begin{tabular}{lcccc}
\toprule
$k$ & Grad. Desc. & Task Retr. & Ind. Heads & Oracle \\
\midrule
0 & 0.204 & 0.193 & 0.206 & 0.937 \\
1 & 0.234 & 0.277 & 0.215 & 0.930 \\
4 & 0.302 & 0.776 & 0.291 & 0.933 \\
8 & 0.361 & 0.936 & 0.328 & 0.936 \\
32 & 0.488 & 0.923 & 0.425 & 0.923 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{figures/icl_accuracy.png}
\caption{ICL accuracy vs. demonstration count for three mechanisms and oracle. Task retrieval reaches oracle performance at $k=8$.}
\label{fig:accuracy}
\end{figure}

Table~\ref{tab:accuracy} and Figure~\ref{fig:accuracy} show that task retrieval achieves the fastest accuracy scaling, matching oracle performance at $k=8$. Implicit gradient descent shows steady improvement but remains below task retrieval. Induction heads provide a moderate baseline.

\subsection{Mechanism-Specific Metrics}

\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{figures/mechanism_scores.png}
\caption{Mechanism-specific scores: gradient alignment (left), task retrieval posterior (center), induction head strength (right).}
\label{fig:scores}
\end{figure}

Figure~\ref{fig:scores} reveals mechanism-specific behavior. The gradient alignment score is constant at 1.0 (by construction, the implicit update perfectly correlates with the explicit gradient). Task retrieval probability increases sharply with demonstrations, saturating near $k=4$. Induction head strength decreases slightly with more demonstrations as attention becomes more distributed.

\subsection{Layer-wise Analysis}

\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{figures/layerwise_contributions.png}
\caption{Relative mechanism contributions across layers. Task retrieval dominates early layers, while induction heads dominate later layers.}
\label{fig:layers}
\end{figure}

Figure~\ref{fig:layers} shows clear depth-dependent specialization. Layer 0 is dominated by task retrieval (50\%), Layer 1--2 show balanced contributions, and Layer 3 is dominated by induction heads (55\%).

\section{Discussion}

Our results support a \emph{multi-mechanism} view of ICL. Task retrieval provides the strongest individual signal, matching the Bayesian inference interpretation~\cite{xie2022explanation}. However, the gradient descent mechanism contributes uniquely through steady improvement with more examples, consistent with the optimization view~\cite{von2023transformers}. Induction heads serve as a pattern-matching substrate that supports both mechanisms.

The depth-dependent specialization suggests that real Transformers likely implement a cascade: early layers identify the task type, middle layers refine predictions through gradient-like updates, and later layers perform pattern matching for final output.

\section{Conclusion}

We provide the first unified comparison of three ICL mechanisms on identical tasks. Task retrieval achieves the best individual performance, but the layer-wise analysis reveals that all three mechanisms contribute in a depth-dependent manner. These results suggest that a complete theory of ICL must account for the interplay between task recognition, implicit optimization, and pattern matching across the Transformer's depth.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
