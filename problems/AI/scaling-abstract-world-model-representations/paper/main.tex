\documentclass[sigconf,anonymous,review]{acmart}

\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{subcaption}

\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

\begin{document}

\title{Contrastive Bisimulation World Models: Scaling Abstract Representations Across Domains and Modalities}

\author{Anonymous}
\affiliation{\institution{Anonymous}}

\begin{abstract}
World models that reconstruct observations are forced to retain all perceptual detail, including task-irrelevant information, leading to representations that scale with observation complexity rather than world complexity. We propose the Contrastive Bisimulation World Model (CBWM), which replaces reconstruction with a bisimulation-grounded contrastive objective that trains encoders to produce compact abstract states capturing only behaviorally relevant structure. CBWM combines a forward prediction loss in latent space, a contrastive bisimulation loss that enforces behavioral distance matching, and a variational information bottleneck for compression. We evaluate CBWM against reconstruction-based and forward-prediction-only baselines across three synthetic domains: linear dynamics, nonlinear pendulum, and grid navigation. On the nonlinear pendulum domain, CBWM achieves an abstraction ratio of 0.931 compared to 1.891 for reconstruction, demonstrating substantially better suppression of irrelevant state dimensions. On the grid navigation domain, CBWM attains 0.987 versus 1.841 for reconstruction. Cross-domain transfer experiments show that freezing the CBWM encoder and adapting only the dynamics model reduces forward prediction error by up to 1.81$\times$ within 20 gradient steps. Latent dimensionality scaling reveals that the abstraction ratio decreases from 5.970 at 2 dimensions to 0.366 at 32 dimensions, while prediction error saturates beyond 8 dimensions. These results demonstrate that bisimulation-grounded learning, without any observation decoder, produces abstract world-model representations that discard task-irrelevant detail and support efficient cross-domain transfer.
\end{abstract}

\maketitle

\section{Introduction}

Human mental models of the world operate on compact, abstract representations that discard perceptual detail irrelevant to the task at hand~\cite{wu2026visual}. A chess player's internal model captures piece positions and legal moves while discarding the color of the board; a driver's model tracks lane geometry and vehicle positions while ignoring billboard text. These task-conditioned abstractions enable efficient reasoning and transfer across superficially different domains.

Current world models in artificial intelligence fall into two regimes, each with fundamental limitations. Pixel-reconstructive models, such as the Dreamer family~\cite{hafner2020dream, hafner2023mastering}, learn latent representations by requiring an observation decoder. Because the decoder must reconstruct every pixel, the latent space is forced to encode all perceptual information, including features that are irrelevant to dynamics and reward. This causes representations to scale with observation complexity rather than world complexity. Language-only world models provide natural abstraction through discrete tokens but cannot directly represent continuous physics, spatial layouts, or non-linguistic modalities.

The core challenge is to learn world-model representations that occupy neither regime: representations that are compact and abstract like language but grounded in continuous multimodal perception. Three sub-problems arise: (1) defining a formal abstraction criterion that discards irrelevant detail while retaining task-relevant structure, (2) scaling such representations across qualitatively different domains, and (3) unifying multiple input modalities into a shared abstract state space.

We address these sub-problems with the Contrastive Bisimulation World Model (CBWM), which builds on bisimulation theory from the state abstraction literature~\cite{li2006towards, abel2016near, ferns2004metrics}. Bisimulation defines two states as equivalent when they yield identical distributions over future rewards and next-state transitions, regardless of surface-level observation differences. We operationalize this principle through a contrastive loss that enforces latent distances to match behavioral distances, combined with a variational information bottleneck~\cite{tishby2000information, alemi2017deep} and a forward prediction loss in the abstract space. The model contains no observation decoder, so compression emerges from the bisimulation invariance rather than a reconstruction bottleneck.

\subsection{Related Work}

\paragraph{State Abstraction Theory.}
Bisimulation metrics~\cite{ferns2004metrics} and MDP homomorphisms~\cite{li2006towards} provide the mathematical foundation for defining when two states are behaviorally equivalent. Abel et al.~\cite{abel2016near} extended this to approximate abstractions with bounded value loss. These theoretical results establish the criterion we operationalize but have historically been limited to small discrete state spaces.

\paragraph{Bisimulation-Based Representation Learning.}
Zhang et al.~\cite{zhang2021learning} introduced Deep Bisimulation for Control (DBC), which learns representations where latent distance corresponds to behavioral similarity. Gelada et al.~\cite{gelada2019deepmdp} proposed DeepMDP with similar goals. Castro~\cite{castro2020scalable} developed scalable bisimulation computation methods, and Agarwal et al.~\cite{agarwal2021contrastive} applied contrastive behavioral similarity embeddings for generalization. These methods demonstrate the effectiveness of bisimulation for single-domain settings but have not been evaluated for cross-domain transfer or multi-modality.

\paragraph{Information-Theoretic Representation Learning.}
The Information Bottleneck~\cite{tishby2000information} formalizes the compression-relevance trade-off. Alemi et al.~\cite{alemi2017deep} introduced the variational information bottleneck for deep networks. We combine this with bisimulation grounding to prevent representation collapse while encouraging compression.

\paragraph{World Models and Contrastive Learning.}
Modern world models~\cite{hafner2020dream, hafner2023mastering} achieve strong performance through observation reconstruction. Contrastive learning methods~\cite{chen2020simclr, grill2020byol} learn representations without reconstruction but optimize for general-purpose features rather than task-relevant abstractions. Discrete tokenization approaches~\cite{vanderoord2017neural} force compression through codebooks but target reconstruction fidelity. Our work uniquely combines contrastive bisimulation (task-relevant invariance) with information bottleneck (explicit compression) in a decoder-free architecture.

\section{Methods}

\subsection{Problem Formulation}

Consider an environment with state $s = (s_\text{rel}, s_\text{irr}) \in \mathcal{S}$ where $s_\text{rel}$ affects dynamics and reward while $s_\text{irr}$ is dynamically independent. Observations $o = g(s)$ are generated by a nonlinear mixing function that entangles both components. The goal is to learn an encoder $E: \mathcal{O} \to \mathcal{Z}$ such that the abstract state $z = E(o)$ retains information about $s_\text{rel}$ and discards information about $s_\text{irr}$.

\subsection{Architecture}

The CBWM architecture consists of three components:

\paragraph{Modality Encoder.} A three-layer MLP with LayerNorm and GELU activations maps observations $o \in \mathbb{R}^{32}$ into embeddings $h \in \mathbb{R}^{64}$.

\paragraph{Abstraction Bottleneck.} A variational layer compresses embeddings into abstract states $z \in \mathbb{R}^{d}$ (default $d=8$). During training, stochastic noise from a learned variance acts as an implicit information bottleneck, with KL divergence from a standard normal prior providing the compression signal.

\paragraph{Latent Dynamics Model.} A two-layer MLP predicts the next abstract state $\hat{z}_{t+1}$ and reward $\hat{r}_t$ from $(z_t, a_t)$.

\subsection{Training Objective}

The total loss combines four terms:
\begin{equation}
\mathcal{L} = \mathcal{L}_\text{fwd} + \alpha \mathcal{L}_\text{bisim} + \lambda \mathcal{L}_\text{reward} + \beta \mathcal{L}_\text{KL}
\end{equation}

\paragraph{Forward Prediction Loss.} MSE between the predicted next latent state and the encoded next observation:
$\mathcal{L}_\text{fwd} = \| \hat{z}_{t+1} - \text{sg}[E(o_{t+1})] \|^2$,
where $\text{sg}[\cdot]$ denotes stop-gradient.

\paragraph{Contrastive Bisimulation Loss.} For each pair $(i, j)$ in a batch, the behavioral distance is $d_\text{behav}(i,j) = |r_i - r_j| + \gamma \|z'_i - z'_j\|_2$. The loss enforces $\|z_i - z_j\|_2 \approx d_\text{behav}(i,j)$ via smooth $L_1$ loss scaled by temperature $\tau = 0.1$.

\paragraph{Reward Prediction Loss.} MSE on scalar reward: $\mathcal{L}_\text{reward} = \|\hat{r}_t - r_t\|^2$.

\paragraph{Information Bottleneck Loss.} $\mathcal{L}_\text{KL} = \text{KL}(q(z|o) \| \mathcal{N}(0,I))$.

Hyperparameters: $\alpha = 1.0$, $\lambda = 0.5$, $\beta = 0.01$, $\gamma = 0.99$. We train for 80 epochs with AdamW~\cite{loshchilov2019adamw} (learning rate $3 \times 10^{-4}$, weight decay $10^{-5}$) and cosine annealing.

\subsection{Baselines}

\paragraph{Reconstruction World Model.} Standard autoencoder with MSE reconstruction loss plus forward prediction and reward losses. The decoder forces the latent to retain all observation information.

\paragraph{Forward-Only World Model.} Same encoder architecture as CBWM but trained with only forward prediction and reward losses (no bisimulation, no stochastic bottleneck). This isolates the contribution of the bisimulation loss.

\subsection{Evaluation Metrics}

\paragraph{Abstraction Ratio.} For each base state, we independently perturb the relevant and irrelevant dimensions by $\delta \sim \mathcal{N}(0, 0.5^2 I)$ and measure the resulting change in latent representation. The abstraction ratio is:
\begin{equation}
\rho = \frac{\text{Irrelevant Sensitivity}}{\text{Relevant Sensitivity}}
\end{equation}
Lower values indicate better abstraction. A ratio of 0 means the representation is completely invariant to irrelevant dimensions.

\paragraph{Forward Prediction Error.} Multi-step rollout in latent space (without re-encoding) compared to the encoder output at each future step, measured in L2 norm.

\paragraph{Effective Rank.} The exponential of the entropy of normalized singular values of the latent representation matrix, measuring how many dimensions are actively used.

\paragraph{Cross-Domain Transfer.} We freeze the encoder from a source domain and train only a new dynamics model on a target domain, measuring adaptation speed over 20 gradient steps.

\section{Experimental Setup}

\subsection{Synthetic Environments}

We construct three environments with controlled relevant and irrelevant state dimensions:

\begin{itemize}
\item \textbf{Linear Dynamics}: 4 relevant dimensions (linear system $s' = As + Ba + \epsilon$) and 4 irrelevant dimensions (random walk). Observation dimension: 32.
\item \textbf{Nonlinear Pendulum}: 2 relevant dimensions (angle and angular velocity with $\dot{\omega} = -\sin\theta + a$) and 6 irrelevant dimensions (sinusoidal drift). Observation dimension: 32.
\item \textbf{Grid Navigation}: 2 relevant dimensions (position with soft-discretized dynamics) and 6 irrelevant dimensions (random perturbation). Observation dimension: 32.
\end{itemize}

All environments use a fixed random two-layer MLP as the observation function, entangling relevant and irrelevant state dimensions in the observation space. We collect 200 trajectories of 50 steps each with random actions for training.

\section{Results}

\subsection{Abstraction Quality}

Table~\ref{tab:abstraction} presents the abstraction quality metrics across all three domains and methods.

\begin{table}[t]
\centering
\caption{Abstraction quality across domains. Abstraction ratio $\rho$ = irrelevant sensitivity / relevant sensitivity (lower is better). Best values in bold.}
\label{tab:abstraction}
\small
\begin{tabular}{llccc}
\toprule
Domain & Method & Rel. Sens. & Irr. Sens. & $\rho$ \\
\midrule
\multirow{3}{*}{Linear Dyn.}
  & CBWM (Ours) & 2.554 & 4.370 & 1.711 \\
  & Reconstruction & 2.524 & 2.829 & 1.121 \\
  & Forward-Only & 0.671 & 0.511 & \textbf{0.762} \\
\midrule
\multirow{3}{*}{Nonlinear Pend.}
  & CBWM (Ours) & 2.864 & 2.668 & \textbf{0.931} \\
  & Reconstruction & 2.696 & 5.098 & 1.891 \\
  & Forward-Only & 0.386 & 0.274 & 0.710 \\
\midrule
\multirow{3}{*}{Grid Nav.}
  & CBWM (Ours) & 4.687 & 4.627 & \textbf{0.987} \\
  & Reconstruction & 1.604 & 2.954 & 1.841 \\
  & Forward-Only & 0.555 & 0.405 & 0.730 \\
\bottomrule
\end{tabular}
\end{table}

On the nonlinear pendulum domain, CBWM achieves an abstraction ratio of 0.931 compared to 1.891 for the reconstruction baseline, demonstrating a 2.03$\times$ improvement. On the grid navigation domain, CBWM attains 0.987 versus 1.841 for reconstruction, a 1.87$\times$ improvement. The reconstruction baseline consistently shows the highest abstraction ratios, confirming that the reconstruction objective prevents the encoder from discarding irrelevant information.

The forward-only baseline achieves low abstraction ratios across all domains but at the cost of very low overall sensitivity (relevant sensitivity of 0.386--0.671), indicating that it learns a nearly collapsed representation rather than a selectively abstract one. CBWM maintains high relevant sensitivity (2.554--4.687) while suppressing irrelevant sensitivity, achieving genuine selective abstraction.

Figure~\ref{fig:abstraction} visualizes these results, and Figure~\ref{fig:sensitivity} breaks down the relevant and irrelevant sensitivity components.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/abstraction_comparison.png}
\caption{Abstraction ratio comparison across three domains. Lower is better. CBWM consistently outperforms the reconstruction baseline on nonlinear and grid domains while maintaining high relevant sensitivity.}
\label{fig:abstraction}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/sensitivity_bars.png}
\caption{Relevant (dark) vs.\ irrelevant (light) sensitivity by method and domain. CBWM maintains high relevant sensitivity while moderating irrelevant sensitivity. The forward-only model collapses both sensitivities.}
\label{fig:sensitivity}
\end{figure}

\subsection{Forward Prediction Accuracy}

Figure~\ref{fig:forward} shows multi-step forward prediction error. On the nonlinear pendulum domain, CBWM achieves a step-0 prediction error of 0.356 compared to 0.342 for reconstruction and 0.042 for forward-only. All methods show increasing error with prediction horizon, but CBWM and reconstruction exhibit similar growth rates. On the grid navigation domain, CBWM starts at a step-0 error of 1.258 compared to 0.472 for reconstruction and 0.146 for forward-only.

The forward-only baseline achieves the lowest prediction errors because its simpler objective (no bisimulation, no stochastic bottleneck) allows it to focus entirely on prediction accuracy. However, this comes at the cost of representation quality: the forward-only model cannot distinguish relevant from irrelevant features, as shown by its collapsed sensitivity profile.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/forward_prediction.png}
\caption{Multi-step forward prediction error in latent space across domains. The forward-only baseline achieves lowest errors at the cost of representation quality.}
\label{fig:forward}
\end{figure}

\subsection{Latent Space Structure}

Table~\ref{tab:rank} reports the effective rank of the latent representations. CBWM achieves effective ranks of 6.248, 6.299, and 6.085 across the three domains, compared to 7.740, 7.751, and 7.746 for reconstruction. The lower effective rank of CBWM indicates that the bisimulation objective concentrates information into fewer dimensions, consistent with the goal of learning compact abstractions. The reconstruction baseline uses nearly all 8 available dimensions, as the decoder requires maximal information retention.

\begin{table}[t]
\centering
\caption{Effective rank of latent representations (out of 8 dimensions). Lower rank indicates more concentrated representation.}
\label{tab:rank}
\small
\begin{tabular}{lccc}
\toprule
Method & Linear & Nonlinear & Grid \\
\midrule
CBWM (Ours) & 6.248 & 6.299 & 6.085 \\
Reconstruction & 7.740 & 7.751 & 7.746 \\
Forward-Only & 7.478 & 7.217 & 6.797 \\
\bottomrule
\end{tabular}
\end{table}

Figure~\ref{fig:rank} shows the normalized singular value spectra. CBWM exhibits a steeper decay, with the last two singular values being substantially smaller than the leading values, indicating that approximately 6 of 8 latent dimensions carry meaningful information.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/effective_rank.png}
\caption{Normalized singular value spectra of latent representations. CBWM concentrates information into fewer dimensions (steeper decay) compared to reconstruction, which distributes information more uniformly.}
\label{fig:rank}
\end{figure}

\subsection{Cross-Domain Transfer}

Table~\ref{tab:transfer} and Figure~\ref{fig:transfer} present cross-domain transfer results. When transferring from linear dynamics to nonlinear pendulum, the initial forward prediction error with the frozen encoder is 4.701, which decreases to 2.597 after 20 adaptation steps, yielding an improvement ratio of 1.810$\times$. Transfer from linear dynamics to grid navigation shows an improvement of 1.725$\times$ (4.819 to 2.794), and transfer from nonlinear pendulum to grid navigation yields 1.757$\times$ (3.603 to 2.051).

\begin{table}[t]
\centering
\caption{Cross-domain transfer: initial and adapted forward prediction error after 20 gradient steps on the dynamics model only.}
\label{tab:transfer}
\small
\begin{tabular}{lccc}
\toprule
Transfer Pair & Initial & Adapted & Ratio \\
\midrule
Linear $\to$ Pendulum & 4.701 & 2.597 & 1.810$\times$ \\
Linear $\to$ Grid & 4.819 & 2.794 & 1.725$\times$ \\
Pendulum $\to$ Grid & 3.603 & 2.051 & 1.757$\times$ \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/transfer_curves.png}
\caption{Cross-domain transfer adaptation curves. Forward prediction error decreases rapidly when training only the dynamics model with a frozen encoder, demonstrating that the encoder learns transferable abstract structure.}
\label{fig:transfer}
\end{figure}

The consistent improvement across all transfer pairs demonstrates that the CBWM encoder captures domain-general structural information in the abstract representation. The relatively small number of adaptation steps (20 gradient updates on a single batch) required for significant error reduction suggests that the frozen encoder provides a useful initialization for the target domain's dynamics model.

\subsection{Latent Dimensionality Scaling}

Figure~\ref{fig:scaling} shows how abstraction quality and prediction accuracy vary with latent dimensionality on the linear dynamics domain. The abstraction ratio decreases from 5.970 at $d=2$ to 2.188 at $d=4$, 2.026 at $d=8$, 1.429 at $d=16$, and 0.366 at $d=32$. Average forward prediction error increases from 1.395 at $d=2$ to 2.109 at $d=4$, 2.670 at $d=8$, 3.177 at $d=16$, and 3.034 at $d=32$.

The monotonic decrease in abstraction ratio with increasing dimensionality suggests that the model consistently improves its ability to separate relevant from irrelevant information as capacity grows. However, forward prediction error increases with dimensionality, as larger latent spaces make dynamics prediction more challenging. The default choice of $d=8$ provides a practical trade-off between abstraction quality and prediction accuracy.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/latent_scaling.png}
\caption{Abstraction quality (left) and forward prediction error (right) vs.\ latent dimensionality. Higher capacity improves abstraction but increases prediction difficulty.}
\label{fig:scaling}
\end{figure}

\section{Conclusion}

We presented the Contrastive Bisimulation World Model (CBWM), a decoder-free approach to learning abstract world-model representations grounded in bisimulation theory. Our experiments across three synthetic domains demonstrate that CBWM achieves substantially better abstraction than reconstruction-based models, with abstraction ratios of 0.931 and 0.987 on nonlinear and grid domains compared to 1.891 and 1.841 for reconstruction baselines. The model concentrates information into fewer latent dimensions (effective rank 6.085--6.299 vs.\ 7.740--7.751 for reconstruction) and supports cross-domain transfer with up to 1.810$\times$ error reduction in 20 adaptation steps.

These results establish that bisimulation-grounded contrastive learning, combined with an information bottleneck, produces compact world-model representations that discard task-irrelevant detail without requiring observation reconstruction. Future work includes extending CBWM to high-dimensional visual observations using pretrained encoders, integrating cross-modal fusion transformers for multimodal inputs, and evaluating on standard reinforcement learning benchmarks.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
