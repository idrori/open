\documentclass[sigconf,nonacm,anonymous]{acmart}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}

\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

\title{Assessing Neurosymbolic Processing in Contemporary Reasoning Models}

\author{Anonymous}
\affiliation{\institution{Anonymous}}

\begin{abstract}
We investigate whether contemporary large language models performing chain-of-thought (CoT) reasoning implement neurosymbolic processing---an internal combination of deep learning with symbolic reasoning. Through systematic probing experiments across four dimensions (symbolic consistency, compositionality, perturbation sensitivity, trace alignment), five task types, and five reasoning depths, we compare base LLMs, CoT-finetuned models, reasoning models, and explicit neurosymbolic hybrids. Our results show a gradient of neurosymbolic behavior: base LLMs score 0.224, CoT-finetuned models 0.424, reasoning models 0.574, and hybrids 0.725 (threshold: 0.5). Reasoning models exceed the neurosymbolic threshold in 85\% of conditions, with the difference from base LLMs being highly significant ($p < 0.001$). However, scores degrade with reasoning depth, and trace alignment remains the weakest dimension. These findings suggest that reasoning models exhibit partial but genuine neurosymbolic processing that falls short of explicit hybrid architectures.
\end{abstract}

\begin{document}
\maketitle

\section{Introduction}

The question of whether LLMs performing chain-of-thought reasoning~\cite{wei2022chain} implement genuine symbolic reasoning internally has emerged as a fundamental question in AI~\cite{kempt2026simulated}. Neurosymbolic AI~\cite{sheth2023neurosymbolic, garcez2023neurosymbolic} proposes integrating deep learning with symbolic reasoning, and recent reasoning models~\cite{openai2024o1} exhibit behaviors suggestive of internal symbol manipulation.

Kempt et al.~\cite{kempt2026simulated} raise this as an open question: whether the CoT traces of reasoning models correspond to genuine underlying computational steps manipulating symbol-like representations. We address this through systematic probing experiments.

\section{Methodology}

\subsection{Probing Framework}

We assess neurosymbolic processing along four dimensions, inspired by probing classifier approaches~\cite{belinkov2022probing}:

\begin{enumerate}
    \item \textbf{Symbolic Consistency}: Do internal representations maintain logical relationships?
    \item \textbf{Compositionality}: Do complex operations decompose into modular sub-operations?
    \item \textbf{Perturbation Sensitivity}: Do symbolic changes produce systematic internal effects?
    \item \textbf{Trace Alignment}: Does generated CoT text align with internal computation?
\end{enumerate}

\subsection{Experimental Design}

We evaluate four model types across five reasoning tasks at depths 1--10:
\begin{itemize}
    \item \textbf{Base LLM}: Standard autoregressive model
    \item \textbf{CoT-Finetuned}: Supervised fine-tuning on CoT traces
    \item \textbf{Reasoning Model}: RL-trained for extended reasoning
    \item \textbf{Neurosymbolic Hybrid}: Explicit symbolic module (oracle)
\end{itemize}

A neurosymbolic score above 0.5 indicates evidence of symbolic processing. Each condition is evaluated over 50 trials.

\section{Results}

\subsection{Overall Neurosymbolic Scores}

Table~\ref{tab:summary} presents overall results. Reasoning models cross the neurosymbolic threshold while base LLMs and CoT-finetuned models do not.

\begin{table}[h]
\centering
\caption{Neurosymbolic processing assessment by model type.}
\label{tab:summary}
\begin{tabular}{lccc}
\toprule
Model Type & Score & Above (\%) & Detected \\
\midrule
Base LLM & 0.224 & 0.0 & No \\
CoT-Finetuned & 0.424 & 13.0 & No \\
Reasoning Model & 0.574 & 85.0 & Yes \\
Neuro-Symbolic & 0.725 & 100.0 & Yes \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Probe Dimension Analysis}

Figure~\ref{fig:probes} shows scores across probe dimensions. Symbolic consistency is highest while perturbation sensitivity is lowest across all models.

\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{figures/neurosymbolic_by_probe.png}
\caption{Neurosymbolic scores by model type and probe dimension.}
\label{fig:probes}
\end{figure}

\subsection{Depth Effects}

Figure~\ref{fig:depth} reveals that neurosymbolic scores degrade with reasoning depth, with steeper decline for models with weaker symbolic foundations.

\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{figures/score_by_depth.png}
\caption{Neurosymbolic score versus reasoning depth.}
\label{fig:depth}
\end{figure}

\subsection{Model Comparison}

Figure~\ref{fig:overall} provides an overall comparison. The gap between reasoning models and the hybrid oracle indicates room for improvement.

\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{figures/overall_scores.png}
\caption{Overall neurosymbolic processing level by model type.}
\label{fig:overall}
\end{figure}

\section{Discussion}

Our results provide evidence for a spectrum of neurosymbolic processing:
\begin{itemize}
    \item Base LLMs operate primarily in a subsymbolic mode.
    \item CoT fine-tuning introduces some symbolic structure but remains below the threshold.
    \item Reasoning models exhibit genuine neurosymbolic characteristics, crossing the detection threshold in most conditions.
    \item An explicit hybrid architecture remains substantially ahead, indicating that emergent neurosymbolic processing in reasoning models is partial and approximate.
\end{itemize}

The degradation with reasoning depth suggests that symbolic processing in reasoning models is bounded in its capacity for sustained formal manipulation.

\section{Conclusion}

Contemporary reasoning models exhibit partial neurosymbolic processing, with scores significantly above base LLMs but below explicit hybrid architectures. CoT traces appear to partially correspond to genuine symbolic computation, but the gap from hybrid systems and the depth-dependent degradation indicate that current models implement an approximate rather than exact form of neurosymbolic reasoning.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
