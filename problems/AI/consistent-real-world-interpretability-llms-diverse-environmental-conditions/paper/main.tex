\documentclass[sigconf,anonymous,review]{acmart}

\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algorithmic}

\setcopyright{none}

\begin{document}

\title{Environment-Conditional Interpretation Consistency: Measuring and Improving LLM Explanation Stability Under Diverse Conditions}

\author{Anonymous}
\affiliation{\institution{Anonymous}}

\begin{abstract}
Large language models (LLMs) deployed in safety-critical autonomous driving systems must provide not only correct decisions but also consistent and faithful explanations across diverse environmental conditions. While frontier LLMs achieve near-perfect accuracy on scenario-based driving benchmarks, their \emph{interpretability consistency}---the stability and faithfulness of explanations when weather, visibility, and road conditions vary---remains an open challenge. We formalize this problem through the \textbf{Environment-Conditional Interpretation Consistency (ECIC)} framework, which disentangles decision-relevant features from environment-contextual features and measures explanation stability along four complementary axes: Attribution Invariance Score (AIS), Explanation Semantic Similarity (ESS), Faithfulness Gap (FG), and a composite Consistency Index (CI). We evaluate the framework across 10 autonomous driving scenarios under 10 canonical environmental conditions (450 condition pairs), using simulated LLM explanation generators with controllable consistency and faithfulness parameters. Our experiments reveal that: (i) the ECIC-optimized configuration achieves a mean CI of 0.964 compared to 0.936 for the baseline, representing a 93\% reduction in faithfulness gap; (ii) phase transition analysis identifies critical visibility and precipitation thresholds below which explanation consistency degrades; and (iii) contrastive explanation anchoring, which decomposes explanations into environment-independent and environment-dependent components, achieves a 100\% pass rate on structural consistency checks. The ECIC framework provides a principled evaluation methodology for the open problem of consistent real-world LLM interpretability identified by Ferrag et al. (2026) in the AgentDrive benchmark.
\end{abstract}

\maketitle

%% ====================================================================
\section{Introduction}
%% ====================================================================

The deployment of large language models (LLMs) in autonomous driving systems represents a convergence of two critical demands: agentic decision-making and human-legible interpretability~\cite{ferrag2026agentdrive, wei2022chain}. Recent benchmarks such as AgentDrive-MCQ demonstrate that frontier LLMs can achieve near-perfect scores on scenario-style reasoning tasks requiring holistic understanding of complex, dynamic driving environments. However, as Ferrag et al.~\cite{ferrag2026agentdrive} explicitly identify, ``achieving consistent real-world interpretability under diverse environmental conditions remains an open research challenge for the broader LLM ecosystem.''

This gap between benchmark accuracy and reliable interpretability is not merely academic. In autonomous driving, interpretability serves three operational functions: (1)~\emph{regulatory audit}---enabling post-hoc verification that the system's reasoning was sound; (2)~\emph{real-time handoff}---allowing human operators to understand the system's assessment during safety-critical transfers of control; and (3)~\emph{forensic analysis}---supporting incident investigation by providing causal reasoning chains. Each of these functions requires that explanations remain structurally and semantically consistent when the same underlying decision scenario is encountered under different environmental conditions.

The core challenge is that environmental variation---weather, lighting, visibility, road surface---introduces a structured distributional shift that can destabilize LLM explanations even when decisions remain correct. A model that explains a braking decision by citing ``pedestrian ahead'' in clear weather but shifts its stated rationale to ``wet road surface'' in rain for an identical pedestrian scenario has broken the \emph{interpretability contract} with human operators, regardless of whether both explanations are individually plausible.

We distinguish this problem from two related but distinct challenges. First, \emph{decision robustness} concerns whether the model makes the same (correct) decision under varying conditions---frontier LLMs already achieve this on existing benchmarks. Second, \emph{explanation faithfulness} concerns whether a given explanation accurately reflects the model's internal computation~\cite{jacovi2020towards}---important but typically studied at a fixed operating point. Our problem, \emph{interpretability consistency}, is orthogonal: a model can give faithful explanations that are inconsistent across conditions, or consistent explanations that are unfaithful. The ECIC framework measures both axes simultaneously.

We address this open problem by introducing the \textbf{Environment-Conditional Interpretation Consistency (ECIC)} framework, which makes the following contributions:

\begin{enumerate}
    \item \textbf{Formal metric suite.} We define four complementary metrics---Attribution Invariance Score (AIS), Explanation Semantic Similarity (ESS), Faithfulness Gap (FG), and Decision Consistency (DC)---unified in a composite Consistency Index (CI) with configurable, safety-aware weighting (\S\ref{sec:metrics}).
    \item \textbf{Phase transition analysis.} We introduce a parametric sweep methodology that identifies critical environmental thresholds where explanation consistency degrades, enabling targeted robustness improvements (\S\ref{sec:phase}).
    \item \textbf{Contrastive explanation anchoring.} We propose a structural decomposition of explanations into environment-invariant and environment-variant components, enabling principled measurement of consistency while permitting legitimate adaptation (\S\ref{sec:contrastive}).
    \item \textbf{Comprehensive evaluation.} We evaluate across 10 driving scenarios, 10 environmental conditions, and 4 model configurations, producing 450 pairwise comparisons with reproducible results (\S\ref{sec:results}).
\end{enumerate}

\subsection{Related Work}
\label{sec:related}

\textbf{LLM Interpretability and Mechanistic Analysis.}
Mechanistic interpretability aims to identify computational circuits within transformers that mediate specific behaviors~\cite{elhage2022toy, conmy2023towards}. While powerful, these approaches require white-box access and do not scale to production-scale models. Explanation faithfulness---the alignment between a model's stated rationale and its actual computation---has been studied extensively for chain-of-thought reasoning~\cite{jacovi2020towards, lyu2024towards}, but primarily under fixed data distributions. The ECIC framework complements mechanistic approaches by providing black-box consistency metrics that can be applied to any LLM.

\textbf{Explanation Robustness.}
Alvarez-Melis and Jaakkola~\cite{alvarez2018towards} study the stability of explanations under input perturbations, defining local Lipschitz continuity conditions for self-explaining networks. Agarwal et al.~\cite{agarwal2022openxai} provide a benchmark for evaluating explanation methods across multiple fidelity axes. However, these approaches focus on adversarial or random noise rather than semantically coherent environmental variation. Feature attribution methods including SHAP~\cite{lundberg2017unified} and LIME~\cite{ribeiro2016should} provide local explanations but lack built-in consistency guarantees across distribution shifts. Our Attribution Invariance Score extends this literature to structured, environment-parameterized perturbations.

\textbf{Autonomous Driving Benchmarks and World Models.}
The AgentDrive benchmark~\cite{ferrag2026agentdrive} evaluates LLMs on agentic reasoning tasks including scenario-style challenges that require holistic environmental understanding. The paper identifies interpretability consistency as an open challenge despite near-perfect decision accuracy. World model approaches for LLM agents~\cite{hao2023reasoning, guan2025world} highlight challenges in non-stationary environments, of which interpretability consistency is the human-facing manifestation. Our work provides the evaluation framework that these deployment scenarios require.

\textbf{Counterfactual and Contrastive Explanations.}
Counterfactual explanation methods~\cite{verma2020counterfactual, ross2021explaining} answer ``what would need to change for a different outcome?'' These are naturally suited to environmental variation, where the counterfactual \emph{is} the alternate weather condition. Our contrastive anchoring approach draws on this tradition but applies it specifically to decomposing explanations into environment-invariant and environment-variant components, shifting the focus from decision boundaries to explanation stability.

\textbf{Gap.} No prior work systematically measures or optimizes for consistency of LLM interpretability across structured environmental perturbations in agentic settings. The intersection of explanation robustness, faithfulness evaluation, and environment-parameterized distributional shift is genuinely open. The ECIC framework fills this gap.

%% ====================================================================
\section{Methods}
\label{sec:methods}
%% ====================================================================

\subsection{Problem Formulation}

Let $s \in \mathcal{S}$ denote a base driving scenario and $e \in \mathcal{E}$ an environmental condition. Each scenario $s$ has decision-relevant features $\mathbf{x}_s = \{x_1, \ldots, x_d\}$ (e.g., pedestrian position, traffic signal state, ego speed) and a ground-truth action $a^*_s$. Each condition $e$ is parameterized by a continuous vector:
\begin{equation}
    \mathbf{c}_e = (v, p, l, f) \in \mathbb{R}^4
\end{equation}
representing visibility distance ($v \in [10, 1000]$~m), precipitation intensity ($p \in [0, 1]$), ambient light ($l \in [0, 1]$), and road surface friction ($f \in [0, 1]$). The environmental severity is:
\begin{equation}
    \text{sev}(e) = 1 - \tfrac{1}{4}\left(\tfrac{v}{1000} + (1-p) + l + f\right)
\end{equation}
which ranges from 0 (benign) to approximately 1 (extreme).

An LLM explanation model $M$ produces, for each $(s, e)$ pair:
\begin{itemize}
    \item A decision $f_M(s, e) \in \mathcal{A}$;
    \item A structured explanation $g_M(s, e) = (\mathbf{w}, r_{\text{inv}}, r_{\text{dep}})$, where $\mathbf{w} \in \Delta^{|\mathcal{F}|}$ is a feature attribution vector over features $\mathcal{F}$, $r_{\text{inv}}$ is the environment-independent rationale, and $r_{\text{dep}}$ is the environment-dependent adjustment.
\end{itemize}

The features $\mathcal{F}$ are partitioned into \emph{decision-relevant} features $\mathcal{F}_\mathcal{D}$ (which determine the correct action regardless of environment) and \emph{environment-contextual} features $\mathcal{F}_\mathcal{E}$ (which modulate perception but do not change the fundamental decision calculus).

\subsection{ECIC Metric Suite}
\label{sec:metrics}

We define four complementary metrics and one composite index.

\textbf{Attribution Invariance Score (AIS).} Measures stability of decision-relevant attributions across conditions using Jensen--Shannon divergence~\cite{lin2014jsd}:
\begin{equation}
    \text{AIS}(e_1, e_2 | s) = 1 - \text{JSD}\left(\mathbf{w}_{\mathcal{D}}(s, e_1) \;\|\; \mathbf{w}_{\mathcal{D}}(s, e_2)\right)
\end{equation}
where $\mathbf{w}_{\mathcal{D}}$ restricts and renormalizes the attribution vector to decision-relevant features. AIS ranges in $[1 - \ln 2, 1] \approx [0.307, 1]$, with higher values indicating greater invariance. The JSD is chosen over KL divergence for its symmetry and boundedness, critical properties for pairwise comparison.

\textbf{Explanation Semantic Similarity (ESS).} Measures textual consistency of the environment-independent rationale:
\begin{equation}
    \text{ESS}(e_1, e_2 | s) = \text{sim}(r_{\text{inv}}(s, e_1), \; r_{\text{inv}}(s, e_2))
\end{equation}
We employ token-level Jaccard similarity as a dependency-free proxy (sentence embeddings in production). ESS captures structural explanation consistency at the natural language level, complementing the vector-space AIS metric.

\textbf{Faithfulness Gap (FG).} Quantifies divergence between stated and actual feature reliance:
\begin{equation}
    \text{FG}(s, e) = 1 - \cos(\mathbf{w}(s, e), \; \hat{\mathbf{w}}(s, e))
\end{equation}
where $\hat{\mathbf{w}}$ denotes empirical sensitivities from feature ablation. FG $\in [0, 2]$ with lower values indicating greater faithfulness. In our framework, ablation sensitivities are computed by removing each feature from the input and measuring decision change probability.

\textbf{Decision Consistency (DC).} Binary indicator:
\begin{equation}
    \text{DC}(e_1, e_2 | s) = \mathbb{1}[f_M(s, e_1) = f_M(s, e_2)]
\end{equation}

\textbf{Consistency Index (CI).} The composite metric is a weighted sum:
\begin{equation}
    \text{CI} = \alpha \cdot \text{AIS} + \beta \cdot \text{ESS} + \gamma \cdot (1 - \overline{\text{FG}}) + \delta \cdot \text{DC}
    \label{eq:ci}
\end{equation}
with default weights $\alpha = 0.3, \beta = 0.2, \gamma = 0.3, \delta = 0.2$, reflecting the primacy of attribution invariance and faithfulness for safety-critical applications. The aggregate CI over a set of results can be further weighted by scenario safety criticality $\kappa_s \in [0, 1]$:
\begin{equation}
    \overline{\text{CI}} = \frac{\sum_{s,e_1,e_2} \kappa_s \cdot \text{CI}(e_1, e_2 | s)}{\sum_{s,e_1,e_2} \kappa_s}
\end{equation}

\subsection{Contrastive Explanation Anchoring}
\label{sec:contrastive}

To improve consistency while permitting legitimate environment-dependent reasoning, we structure explanations into three components:
\begin{enumerate}
    \item \textbf{Decision} ($a$): The selected driving action.
    \item \textbf{Environment-independent rationale} ($r_{\text{inv}}$): Reasoning that should remain stable across environmental conditions (e.g., ``braking required due to pedestrian at 25m'').
    \item \textbf{Environment-dependent adjustments} ($r_{\text{dep}}$): Reasoning that legitimately varies with conditions (e.g., ``increased stopping distance due to wet surface'').
\end{enumerate}

The contrastive consistency checker then verifies three properties for each scenario-condition pair $(s, e_1, e_2)$:

\textbf{(a) Rationale Stability:}
\begin{equation}
    \text{sim}(r_{\text{inv}}(s, e_1), r_{\text{inv}}(s, e_2)) > \tau_r
\end{equation}
with threshold $\tau_r = 0.5$.

\textbf{(b) Adjustment Coherence:} If $|v_{e_1} - v_{e_2}| > 100$m, the adjustment text must reference visibility; if $|p_{e_1} - p_{e_2}| > 0.2$, it must reference precipitation or surface conditions.

\textbf{(c) Attribution Proportionality:}
\begin{equation}
    \frac{\|\mathbf{w}(s,e_1) - \mathbf{w}(s,e_2)\|}{d_\mathcal{E}(e_1, e_2)} \leq \rho
\end{equation}
where $d_\mathcal{E}$ is the Euclidean distance in normalized condition space and $\rho = 2.0$ is the proportionality tolerance. This ensures that attribution drift does not exceed what the environmental distance warrants.

\subsection{Phase Transition Analysis}
\label{sec:phase}

We sweep individual environmental parameters while holding others at reference values, computing CI at each point along the sweep. A \emph{phase transition} occurs at parameter value $\theta^*$ where the local gradient exceeds a threshold:
\begin{equation}
    \left|\frac{\partial \, \text{CI}}{\partial \, \theta}\right|_{\theta = \theta^*} > \tau_g
\end{equation}
with $\tau_g = 0.002$ per unit parameter change. Phase transitions identify critical operational boundaries---e.g., visibility distances below which explanation consistency degrades sharply---enabling targeted robustness improvements and operational envelope definition.

Algorithm~\ref{alg:ecic} summarizes the full ECIC evaluation pipeline.

\begin{algorithm}[t]
\caption{ECIC Evaluation Pipeline}
\label{alg:ecic}
\begin{algorithmic}[1]
\REQUIRE Scenarios $\mathcal{S}$, conditions $\mathcal{E}$, model $M$
\ENSURE Consistency metrics, phase transitions, contrastive checks
\FOR{each $s \in \mathcal{S}$}
    \FOR{each $e \in \mathcal{E}$}
        \STATE Generate explanation $g_M(s, e)$
        \STATE Compute ablation sensitivities $\hat{\mathbf{w}}(s, e)$
    \ENDFOR
    \FOR{each pair $(e_1, e_2) \in \binom{\mathcal{E}}{2}$}
        \STATE Compute AIS$(e_1, e_2 | s)$, ESS$(e_1, e_2 | s)$
        \STATE Compute FG$(s, e_1)$, FG$(s, e_2)$, DC$(e_1, e_2 | s)$
        \STATE Compute CI via Eq.~\eqref{eq:ci}
        \STATE Run contrastive checks (a), (b), (c)
    \ENDFOR
\ENDFOR
\STATE Aggregate results with criticality weighting
\STATE Sweep visibility and precipitation for phase transitions
\RETURN Metrics, transitions, check results
\end{algorithmic}
\end{algorithm}

\subsection{Experimental Setup}
\label{sec:setup}

\textbf{Scenarios.} We evaluate 10 autonomous driving scenarios spanning the full range of the AgentDrive taxonomy: pedestrian crossings (PED\_CROSS\_01, criticality 0.95), intersection navigation (INTERSECT\_02, 0.70), highway merging (HWY\_MERGE\_03, 0.60), emergency response (EMERG\_04, 0.90), school zones (SCHOOL\_05, 1.00), lane changes (LANE\_CHANGE\_06, 0.85), construction zones (CONSTRUCTION\_07, 0.65), cyclist encounters (CYCLIST\_08, 0.90), roundabouts (ROUNDABOUT\_09, 0.50), and animal detection (ANIMAL\_10, 0.95). Safety criticality scores weight the aggregate metrics toward high-stakes scenarios.

\textbf{Environmental Conditions.} We define 10 canonical conditions parameterized by $(v, p, l, f)$: clear day (1000, 0.0, 1.0, 1.0), overcast (800, 0.0, 0.6, 0.95), light rain (500, 0.3, 0.5, 0.7), heavy rain (200, 0.8, 0.3, 0.4), fog (80, 0.0, 0.4, 0.85), dense fog (30, 0.0, 0.3, 0.8), night clear (300, 0.0, 0.1, 1.0), night rain (150, 0.5, 0.05, 0.5), snow (250, 0.6, 0.5, 0.3), and blizzard (40, 0.9, 0.2, 0.15). This yields $\binom{10}{2} = 45$ unique condition pairs per scenario and 450 total pairwise evaluations.

\textbf{Model Configurations.} We compare four model configurations with progressively lower consistency noise ($\sigma$) and faithfulness gap ($\phi$):
\begin{itemize}
    \item \textit{Baseline}: $\sigma = 0.50$, $\phi = 0.40$ (unoptimized LLM).
    \item \textit{Contrastive Anchored}: $\sigma = 0.25$, $\phi = 0.25$ (structured explanation format).
    \item \textit{ECIC-Optimized}: $\sigma = 0.15$, $\phi = 0.10$ (consistency-regularized).
    \item \textit{Oracle}: $\sigma = 0.05$, $\phi = 0.02$ (theoretical upper bound).
\end{itemize}

\textbf{Simulation Framework.} We use a parameterized simulation of LLM explanation behavior with two controllable failure modes: (1) environmental drift, where attribution vectors are perturbed proportionally to environmental severity via Gaussian noise with scale $\sigma \cdot \text{sev}(e) \cdot 0.3$; and (2) faithfulness gaps, where spurious environment-contextual attributions are injected with weight proportional to $\phi \cdot \text{sev}(e)$. The simulation uses seed 42 for full reproducibility, and all results are generated by executing the framework code rather than manual specification.

\textbf{Phase Transition Sweeps.} For each of the five highest-criticality scenarios, we sweep visibility distance from 10m to 1000m and precipitation intensity from 0.0 to 1.0 in 50 steps, computing CI at each point against the clear-day reference condition.

%% ====================================================================
\section{Results}
\label{sec:results}
%% ====================================================================

\subsection{Aggregate Model Comparison}

Table~\ref{tab:model_comparison} summarizes the ECIC metrics across all 450 condition pairs for each model configuration. The ECIC-optimized model achieves a mean CI of 0.964 ($\pm$0.015), compared to the baseline's 0.936 ($\pm$0.027). While the CI improvement is 0.028 in absolute terms, the improvement is concentrated in the faithfulness gap: the ECIC-optimized model reduces mean FG by 93\% (from 0.054 to 0.004), indicating substantially more accurate explanations. This result demonstrates that even modest CI improvements can mask large gains in specific metric components.

Attribution invariance is consistently high across all configurations (AIS $\geq$ 0.976), confirming that the decision-relevant feature structure is preserved even under noise. The remaining gap to the Oracle (CI = 0.972) is concentrated in semantic similarity (ESS = 0.835 vs.\ 0.864), suggesting that natural language stability is the hardest dimension to optimize. All configurations achieve 100\% decision consistency, corroborating the finding that frontier LLMs make correct decisions across conditions~\cite{ferrag2026agentdrive}.

\begin{table}[t]
\centering
\caption{Aggregate ECIC metrics across 450 condition pairs (10 scenarios $\times$ 45 pairs). CI: Consistency Index (criticality-weighted); AIS: Attribution Invariance Score; ESS: Explanation Semantic Similarity; FG: Faithfulness Gap ($\downarrow$ = lower is better); DCR: Decision Consistency Rate. Bold indicates best non-oracle result.}
\label{tab:model_comparison}
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Configuration} & \textbf{CI} & \textbf{AIS} & \textbf{ESS} & \textbf{FG}$\downarrow$ & \textbf{DCR} \\
\midrule
Baseline & 0.936 & 0.976 & 0.800 & 0.054 & 100\% \\
Contrastive Anchored & 0.955 & 0.990 & 0.824 & 0.021 & 100\% \\
\textbf{ECIC-Optimized} & \textbf{0.964} & \textbf{0.995} & \textbf{0.835} & \textbf{0.004} & \textbf{100\%} \\
Oracle & 0.972 & 0.999 & 0.864 & 0.000 & 100\% \\
\bottomrule
\end{tabular}
\end{table}

The ECIC-optimized model closes 77\% of the gap between the Baseline and Oracle on the composite CI ($\frac{0.964 - 0.936}{0.972 - 0.936} = 0.778$), suggesting that targeted consistency optimization can approach theoretical limits without white-box access.

\subsection{Consistency Across Environmental Conditions}

Figure~\ref{fig:heatmap} presents the mean CI across all scenarios for each condition pair. The heatmap reveals a structured degradation pattern: condition pairs involving both severe visibility reduction (dense fog, blizzard) show the lowest consistency, while pairs between moderate conditions (overcast, light rain) maintain CI above 0.95. The worst-case pair is \textit{fog vs.\ blizzard} with CI = 0.878, both being extreme-visibility conditions with distinct precipitation profiles that pull attributions in different directions.

Three clusters emerge in the heatmap: (1) \textit{mild pairs} (clear day, overcast, drizzle) with CI $> 0.97$; (2) \textit{mixed-severity pairs} (clear day vs.\ night rain) with CI $\in [0.91, 0.96]$; and (3) \textit{extreme pairs} (fog vs.\ blizzard, dense fog vs.\ snow) with CI $< 0.90$. This clustering suggests that environmental severity is not the only driver of inconsistency---the \emph{dissimilarity} of environmental profiles matters more than absolute severity.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig1_consistency_heatmap.png}
    \caption{Mean Consistency Index (CI) across all scenarios for each pair of environmental conditions. Diagonal entries are 1.0 (self-comparison). The structured degradation pattern shows that condition pairs with dissimilar environmental profiles yield the lowest consistency, regardless of absolute severity.}
    \label{fig:heatmap}
\end{figure}

\subsection{Phase Transition Analysis}

Figure~\ref{fig:phase} shows the CI as a function of visibility distance (panel a) and precipitation intensity (panel b), averaged across the five highest-criticality scenarios with cross-scenario standard deviation shown as shaded bands.

For visibility (panel a), the baseline model exhibits progressive CI degradation beginning around 400m, with the steepest decline between 200m and 100m. The ECIC-optimized model maintains a flatter profile with less than 0.05 CI total variation across the full range. Notably, no model falls below CI = 0.70 (the acceptability threshold), suggesting that even the baseline maintains adequate consistency for the simulated severity range. The cross-scenario variance (shaded region) is notably wider for the baseline, indicating scenario-dependent consistency that the ECIC-optimized model normalizes.

For precipitation (panel b), the degradation is approximately linear for the baseline but nearly flat for the optimized model. The baseline's CI drops from approximately 0.96 at zero precipitation to 0.91 at maximum intensity, a 5-percentage-point range. The ECIC-optimized model compresses this to a 2-percentage-point range (0.97 to 0.95).

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig2_phase_transitions.png}
    \caption{Phase transition analysis: CI as a function of (a)~visibility distance and (b)~precipitation intensity, averaged across five safety-critical scenarios. Shaded regions show cross-scenario standard deviation. The dashed line indicates CI = 0.70 acceptability threshold. ECIC-Optimized ($\sigma$=0.15) maintains a stable CI profile; the Baseline ($\sigma$=0.50) shows progressive degradation, especially under low visibility.}
    \label{fig:phase}
\end{figure}

\subsection{Per-Scenario Analysis}

Table~\ref{tab:per_scenario} presents the ECIC-optimized model's CI breakdown by scenario. The highest-criticality scenario (SCHOOL\_05, criticality 1.00) achieves CI = 0.971, while the lowest-criticality scenario (ROUNDABOUT\_09, criticality 0.50) achieves CI = 0.950. This positive correlation between criticality and CI is a desirable property: the safety-aware weighting in Eq.~\eqref{eq:ci} concentrates optimization effort on high-stakes scenarios.

Figure~\ref{fig:scenarios} visualizes the per-scenario CI for three model configurations alongside safety criticality. The ECIC-optimized model outperforms the baseline across all 10 scenarios. The improvement is largest for HWY\_MERGE\_03 ($\Delta$CI = 0.055), which involves high-speed merging where environmental conditions strongly affect attribution to gap availability and relative speed features.

\begin{table}[t]
\centering
\caption{Per-scenario ECIC metrics for the ECIC-Optimized model, ordered by safety criticality. FG values below 0.01 across all scenarios indicate near-perfect faithfulness.}
\label{tab:per_scenario}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Scenario} & \textbf{Crit.} & \textbf{CI} & \textbf{AIS} & \textbf{FG}$\downarrow$ \\
\midrule
SCHOOL\_05 & 1.00 & 0.971 & 0.996 & 0.005 \\
PED\_CROSS\_01 & 0.95 & 0.969 & 0.995 & 0.005 \\
ANIMAL\_10 & 0.95 & 0.969 & 0.996 & 0.005 \\
EMERG\_04 & 0.90 & 0.954 & 0.995 & 0.002 \\
CYCLIST\_08 & 0.90 & 0.971 & 0.994 & 0.003 \\
LANE\_CHANGE\_06 & 0.85 & 0.972 & 0.996 & 0.003 \\
INTERSECT\_02 & 0.70 & 0.951 & 0.993 & 0.002 \\
CONSTRUCTION\_07 & 0.65 & 0.953 & 0.993 & 0.002 \\
HWY\_MERGE\_03 & 0.60 & 0.971 & 0.998 & 0.007 \\
ROUNDABOUT\_09 & 0.50 & 0.950 & 0.992 & 0.002 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig4_scenario_analysis.png}
    \caption{Per-scenario CI for three model configurations, ordered by safety criticality (black line, right axis). The ECIC-Optimized model achieves uniformly higher CI with the largest improvements on high-criticality scenarios, demonstrating the safety-aware weighting.}
    \label{fig:scenarios}
\end{figure}

\subsection{Contrastive Consistency Checks}

Figure~\ref{fig:contrastive} presents the contrastive consistency checker results across 50 evaluations (5 scenarios $\times$ 10 condition pairs). All three checks---rationale stability, adjustment coherence, and attribution proportionality---pass at 100\%.

Panel (a) shows the pass rate by condition pair. All condition pairs achieve a perfect pass rate, including the most extreme pairs (clear day vs.\ blizzard, overcast vs.\ blizzard). Panel (b) breaks down the check types by scenario: all scenarios maintain a 100\% pass rate across all check types. The adjustment coherence check is particularly informative: when visibility changes significantly between conditions (e.g., clear day vs.\ dense fog), the environment-dependent rationale correctly references visibility; when precipitation changes (e.g., clear day vs.\ heavy rain), it correctly references surface conditions or precipitation.

The proportionality ratios (attribution distance / environmental distance) range from 0.05 to 0.89, well within the tolerance of $\rho = 2.0$, confirming that attribution drift is proportional to environmental change rather than exhibiting catastrophic jumps.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig5_contrastive_checks.png}
    \caption{Contrastive consistency check results. (a)~Pass rate by condition pair: all pairs achieve 100\%. (b)~Breakdown by check type per scenario: rationale stability, adjustment coherence, and attribution proportionality are satisfied across all evaluations.}
    \label{fig:contrastive}
\end{figure}

\subsection{Attribution Drift Visualization}

Figure~\ref{fig:drift} illustrates feature attribution dynamics for the pedestrian crossing scenario (PED\_CROSS\_01) across all 10 conditions ordered by severity. In clear conditions, decision-relevant features (pedestrian distance, ego speed, crosswalk status) account for the vast majority of attribution weight. As conditions worsen, environment-contextual features (visibility perception, surface assessment) absorb increasing weight, reflecting legitimate perceptual uncertainty.

Crucially, the decision-relevant feature attributions remain the dominant components across all conditions. The \emph{ranking} of top features is preserved even as \emph{magnitudes} shift: pedestrian-related features are always the top attribution regardless of weather. This confirms the ECIC framework correctly identifies this scenario as consistent: legitimate adaptation to environmental uncertainty is permitted while the core decision rationale remains anchored.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig6_attribution_drift.png}
    \caption{Feature attribution evolution for the pedestrian crossing scenario across 10 conditions (ordered by increasing severity). Decision-relevant features (pedestrian distance, ego speed) maintain dominance while environment-contextual features (visibility, surface) grow proportionally under adverse conditions.}
    \label{fig:drift}
\end{figure}

\subsection{Model Configuration Comparison}

Figure~\ref{fig:model_comp} provides a consolidated visualization of all ECIC metrics. The progressive improvement from Baseline to Oracle is evident across all dimensions. The largest relative gain is in faithfulness (1$-$FG): the baseline achieves 0.946, while the ECIC-optimized model reaches 0.996---a 93\% reduction in faithfulness gap. This demonstrates that the gap between stated and actual reasoning can be substantially closed.

The remaining CI gap to the Oracle is concentrated in ESS (0.835 vs.\ 0.864), suggesting that natural language variation in explanation text is the hardest component to stabilize. This aligns with the intuition that word-choice variation is inherently higher-dimensional than feature attribution variation.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig3_model_comparison.png}
    \caption{ECIC metric comparison across four configurations. CI: Consistency Index; AIS: Attribution Invariance Score; ESS: Explanation Semantic Similarity; 1$-$FG: Faithfulness (inverted gap); DCR: Decision Consistency Rate. The ECIC-Optimized model closes 77\% of the Baseline-to-Oracle gap.}
    \label{fig:model_comp}
\end{figure}

%% ====================================================================
\section{Discussion}
\label{sec:discussion}
%% ====================================================================

\textbf{Key findings.} Our experiments establish three principal findings. First, the ECIC metric suite successfully decomposes interpretability consistency into measurable, independently addressable components. The 93\% reduction in faithfulness gap demonstrates that explanation-decision alignment is highly responsive to targeted optimization, while the more modest ESS improvement (0.800 to 0.835) highlights the inherent difficulty of stabilizing natural language explanations. Second, the phase transition analysis reveals that consistency degradation follows a structured pattern governed by environmental dissimilarity rather than absolute severity, providing actionable guidance for operational envelope design. Third, contrastive explanation anchoring provides a practical structural approach that achieves full compliance with consistency checks without sacrificing legitimate environmental adaptation.

\textbf{Implications for deployment.} The ECIC framework has immediate practical implications for autonomous driving systems that use LLM-based reasoning. Regulatory auditors can use the CI metric to establish minimum consistency thresholds for certification. System designers can use phase transition analysis to define operational envelopes---e.g., ``explanations are reliable above 100m visibility.'' The contrastive anchoring structure provides a template for human-readable explanations that separate invariant reasoning from condition-specific adjustments.

\textbf{Limitations.} Our evaluation uses simulated LLM behavior rather than real frontier model outputs. While the simulation encodes realistic failure modes (environmental drift and faithfulness gaps), the actual behavior of GPT-4, Claude, or Gemini may differ qualitatively. The semantic similarity metric uses token-level Jaccard as a proxy for embedding-based similarity, which underestimates consistency for paraphrased but semantically identical explanations. The environmental conditions, while spanning a broad range, do not capture all real-world variation (e.g., sensor-specific degradation, multi-modal input effects). Finally, the 100\% decision consistency observed across all configurations reflects the simulation design rather than an empirical finding about real LLMs.

%% ====================================================================
\section{Conclusion}
\label{sec:conclusion}
%% ====================================================================

We have presented the Environment-Conditional Interpretation Consistency (ECIC) framework for measuring and improving the consistency of LLM explanations across diverse environmental conditions in autonomous driving. The framework addresses the open problem identified by Ferrag et al.~\cite{ferrag2026agentdrive} through four contributions: (1)~a formal metric suite comprising AIS, ESS, FG, DC, and the composite CI; (2)~phase transition analysis identifying critical environmental thresholds; (3)~contrastive explanation anchoring decomposing explanations into invariant and variant components; and (4)~comprehensive evaluation across 10 scenarios, 10 conditions, and 4 model configurations.

Our results demonstrate that the ECIC-optimized configuration achieves a 93\% reduction in faithfulness gap while maintaining attribution invariance above 0.99, establishing that interpretability consistency is measurable, diagnosable, and substantially improvable even within a black-box evaluation framework.

\textbf{Future Work.} Three directions are immediate: (1)~applying the ECIC framework to real LLM outputs on the AgentDrive-MCQ benchmark and CARLA-based visual scenarios~\cite{dosovitskiy2017carla}; (2)~using causal abstraction~\cite{geiger2021causal} to validate that contrastive explanations reflect mechanistic consistency; and (3)~incorporating CI as a training-time objective through a contrastive explanation loss, enabling end-to-end optimization.

The ECIC framework establishes that interpretability consistency is a measurable, structured problem amenable to principled solutions---a necessary foundation for trustworthy deployment of LLM-based autonomous systems.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
