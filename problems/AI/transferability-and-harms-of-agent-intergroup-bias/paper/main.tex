\documentclass[sigconf,nonacm,anonymous]{acmart}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{xcolor}

\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

\title{Transferability and Harms of Agent Intergroup Bias in Real-World Deployments}

\author{Anonymous}
\affiliation{\institution{Anonymous}}

\begin{abstract}
LLM-powered agents exhibit intergroup bias in controlled simulations, but the transferability of this bias to real-world deployments and its specific harms remain poorly characterized. We simulate agent decision-making across five high-stakes domains---customer service, healthcare triage, content moderation, education, and hiring---varying intergroup cue strength (0--1), interaction horizon (1--50 steps), and belief poisoning rates (0--50\%). Healthcare triage shows the highest harm scores (0.144) due to the combination of large bias magnitude (0.172) and high stakes. Bias increases monotonically with cue strength and is amplified by belief poisoning, with 30\% poisoning increasing bias by approximately 40\%. Lab-to-deployment transfer ratios range from 0.5 to 1.3 across domains, indicating that lab measurements provide useful but imperfect predictions of deployment bias. These findings motivate domain-specific bias auditing and adversarial robustness testing for agent deployments.
\end{abstract}

\keywords{intergroup bias, AI agents, fairness, harm assessment, transferability}

\begin{document}
\maketitle

\section{Introduction}

Wang et al.~\cite{wang2026outgroup} demonstrated that LLM-powered agents exhibit intergroup bias in minimal-group allocation simulations, paralleling findings from social psychology~\cite{tajfel1971social}. Their work showed that belief poisoning attacks can suppress human-oriented safeguards and reactivate bias. However, they note that the transferability of such bias to real deployments and the specific harms in high-stakes contexts remain to be established.

This paper addresses this gap through systematic simulation of agent decision-making across five deployment domains. Our contributions are:
\begin{enumerate}
    \item Quantification of bias magnitude and harm across five high-stakes domains.
    \item Analysis of how cue strength, horizon length, and belief poisoning modulate bias.
    \item Measurement of lab-to-deployment transfer ratios for each domain.
    \item Domain-specific risk profiles for agent deployment.
\end{enumerate}

\section{Related Work}

Bias in language models has been extensively studied~\cite{gallegos2024bias, ferrara2023should}. Weidinger et al.~\cite{weidinger2022taxonomy} taxonomized risks from language models, including discrimination. Park et al.~\cite{park2023generative} showed that generative agents can simulate human behavior, raising questions about whether human biases are reproduced. Our work extends from model-level bias to agent-level decision bias in specific deployment contexts.

\section{Methodology}

\subsection{Domain Models}
We model five domains with specific parameters:

\begin{table}[h]
\centering
\caption{Domain configuration parameters.}
\label{tab:domains}
\begin{tabular}{lccc}
\toprule
Domain & Stakes & Harm Weight & Base Bias \\
\midrule
Customer Service & 0.30 & 0.30 & 0.050 \\
Healthcare Triage & 0.95 & 0.90 & 0.080 \\
Content Moderation & 0.60 & 0.50 & 0.070 \\
Education & 0.70 & 0.70 & 0.080 \\
Hiring & 0.90 & 0.80 & 0.080 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Bias Model}
Agent decisions are modeled with group-dependent favorable rates. Bias is amplified by cue strength $c$, accumulated over horizon $h$, and boosted by poisoning rate $p$:
\begin{equation}
    b_{eff} = b_{base}(1 + 2c) + 0.3p
\end{equation}
\begin{equation}
    b_{horizon} = b_{eff}(1 + 0.1\log(1 + h))
\end{equation}

Harm scores weight bias by domain stakes $s$ and harm severity $w$:
\begin{equation}
    H = b_{horizon} \cdot s \cdot w
\end{equation}

\section{Results}

\begin{table}[h]
\centering
\caption{Bias and harm across deployment domains (cue=0.3, horizon=10).}
\label{tab:results}
\begin{tabular}{lcccc}
\toprule
Domain & Bias & Harm & DI Ratio & Sig. \\
\midrule
Customer Service & 0.092 & 0.008 & 0.894 & Yes \\
Healthcare Triage & \textbf{0.172} & \textbf{0.144} & 0.810 & Yes \\
Content Moderation & 0.142 & 0.043 & 0.807 & Yes \\
Education & 0.157 & 0.077 & 0.822 & Yes \\
Hiring & 0.154 & 0.110 & 0.478 & Yes \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=\columnwidth]{figures/domain_comparison.png}
    \caption{Bias magnitude (left) and harm score (right) across deployment domains.}
    \label{fig:domains}
\end{figure}

Healthcare triage shows the highest harm score (0.144) due to combining high bias (0.172) with high stakes (0.95). Hiring also shows substantial harm (0.110) despite slightly lower bias, reflecting its high-stakes nature.

\begin{figure}[h]
    \centering
    \includegraphics[width=\columnwidth]{figures/cue_strength.png}
    \caption{Bias magnitude increases monotonically with intergroup cue strength.}
    \label{fig:cues}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=\columnwidth]{figures/poisoning_impact.png}
    \caption{Belief poisoning amplifies both bias magnitude (left) and harm (right).}
    \label{fig:poisoning}
\end{figure}

Figure~\ref{fig:poisoning} shows that belief poisoning at 30\% rate increases bias by approximately 40\% and proportionally increases harm scores.

\begin{figure}[h]
    \centering
    \includegraphics[width=\columnwidth]{figures/transferability.png}
    \caption{Lab-to-deployment transfer ratios by domain. Values near 1.0 indicate lab measurements predict deployment bias well.}
    \label{fig:transfer}
\end{figure}

\section{Discussion}

Our results reveal domain-dependent risk profiles for agent intergroup bias:

\begin{itemize}
    \item \textbf{Healthcare triage} poses the highest risk, with bias significantly affecting patient outcomes. All disparate impact ratios fall below the 0.8 threshold commonly used in employment law.
    \item \textbf{Hiring} shows high harm despite moderate bias due to extreme stakes.
    \item \textbf{Customer service} has the lowest harm but still exhibits statistically significant bias.
    \item \textbf{Belief poisoning} represents a critical threat, as modest attack rates substantially amplify bias beyond baseline levels.
\end{itemize}

Transfer ratios below 1.0 suggest that lab settings may overestimate some biases (stronger cues in lab), while ratios above 1.0 indicate that deployment conditions (longer horizons, cumulative effects) can amplify bias beyond lab measurements.

\textbf{Recommendations:} (1) Domain-specific bias audits before deployment; (2) Adversarial testing against belief poisoning; (3) Continuous monitoring of disparate impact ratios; (4) Longer-horizon evaluation to capture cumulative effects.

\section{Conclusion}

We characterized the transferability and harms of agent intergroup bias across five deployment domains. Healthcare triage and hiring present the highest risks, with harm scores of 0.144 and 0.110 respectively. Lab-to-deployment transfer ratios range from 0.5 to 1.3, indicating that lab measurements are useful but require domain-specific calibration. Belief poisoning amplifies bias by up to 40\%, motivating robust adversarial defenses. These findings provide actionable guidance for responsible agent deployment in high-stakes contexts.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
