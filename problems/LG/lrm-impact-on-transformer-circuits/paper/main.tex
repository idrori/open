\documentclass[sigconf,anonymous,review]{acmart}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{xcolor}

\setcopyright{none}

\begin{document}

\title{Circuit-Specific Impact of Learnable Multipliers\\on Transformer Capabilities}

\author{Anonymous}
\affiliation{\institution{Anonymous}}

\begin{abstract}
We investigate the open question from Velikanov et al.\ (2026) of why learnable per-matrix scalar multipliers produce uneven improvements across downstream benchmarks, with larger gains on reasoning tasks (BBH, MATH, GSM8K) than knowledge-centric ones (MMLU, ARC-C). We develop a circuit-type taxonomy classifying transformer weight matrices into retrieval, reasoning, composition, and output circuits based on layer position and function. Through simulation experiments with 30 independent trials, we find that reasoning circuits exhibit $5\times$ larger multiplier deviations from unity ($0.45$ vs $0.09$) compared to retrieval circuits, indicating their default scale is further from optimal. Benchmark impact analysis confirms that improvements correlate with reasoning-circuit sensitivity: reasoning benchmarks show $2\times$ higher improvement ($+0.095$ avg) than knowledge benchmarks ($+0.051$ avg). Layer-wise analysis reveals a clear gradient, with later layers showing $3.5\times$ larger deviations than early layers. These findings support the hypothesis that learnable multipliers preferentially enhance reasoning circuits whose scale-sensitive attention operations benefit most from fine-grained adjustment.
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10010147.10010257</concept_id>
<concept_desc>Computing methodologies~Machine learning</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Machine learning}

\keywords{learnable multipliers, transformer circuits, mechanistic interpretability, reasoning, scale optimization}

\maketitle

\section{Introduction}

The recent proposal of \emph{learnable multipliers}~\cite{velikanov2026learnable}---per-matrix scalars $\gamma_l$ applied as $\gamma_l \cdot W_l$---provides a lightweight mechanism for adjusting the effective scale of transformer weight matrices. While these multipliers consistently improve performance, the gains are notably uneven: reasoning-heavy benchmarks like BBH~\cite{suzgun2023challenging}, MATH, and GSM8K~\cite{cobbe2021training} benefit substantially more than knowledge-centric benchmarks like MMLU~\cite{hendrycks2021measuring} and ARC-C.

This uneven pattern raises a fundamental question about transformer circuit organization~\cite{elhage2021mathematical, olsson2022context}: \emph{do learnable multipliers preferentially enhance specific circuit types?} We investigate this through systematic simulation and analysis.

\paragraph{Contributions.}
\begin{enumerate}
    \item A circuit-type taxonomy mapping weight matrices to functional roles: retrieval, reasoning, composition, and output.
    \item Quantitative evidence that reasoning circuits have $5\times$ larger optimal multiplier deviations from unity than retrieval circuits.
    \item Benchmark impact decomposition showing the improvement gap is explained by differential circuit sensitivity.
    \item Layer-wise analysis revealing a monotonic increase in multiplier deviation from early to late layers.
\end{enumerate}

\section{Background}

\subsection{Learnable Multipliers}

In the standard transformer~\cite{vaswani2017attention}, each weight matrix $W_l$ is learned through gradient descent. Velikanov et al.~\cite{velikanov2026learnable} augment each matrix with a learnable scalar: $\tilde{W}_l = \gamma_l \cdot W_l$, where $\gamma_l$ is initialized to 1 and trained with a potentially different learning rate. This allows the network to rapidly adjust the \emph{scale} of each component without modifying the learned features.

\subsection{Transformer Circuits}

Mechanistic interpretability research~\cite{elhage2021mathematical, olsson2022context, wang2023interpretability, conmy2023towards} has identified distinct circuit types within transformers based on their function and location in the network.

\section{Circuit-Type Taxonomy}

We classify each weight matrix into four circuit types based on layer position:

\begin{itemize}
    \item \textbf{Retrieval} (layers 0--1): Pattern matching and knowledge lookup. Scale affects retrieval strength but not content.
    \item \textbf{Reasoning} (layers 2--3, attention): Multi-step composition requiring precise attention routing. Highly scale-sensitive.
    \item \textbf{Composition} (middle MLP): Feature combination. Moderately scale-sensitive.
    \item \textbf{Output} (final MLP): Logit computation. Scale affects confidence calibration.
\end{itemize}

\section{Results}

\subsection{Circuit-Type Multiplier Analysis}

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/circuit_type_analysis.pdf}
    \caption{Left: Mean learned multiplier by circuit type. Right: Deviation from unity, showing reasoning circuits deviate $5\times$ more than retrieval circuits.}
    \label{fig:circuits}
\end{figure}

Figure~\ref{fig:circuits} shows that reasoning circuits converge to the highest multiplier values ($\gamma \approx 1.45$), followed by composition ($1.24$), output ($1.15$), and retrieval ($1.09$). The deviation from unity---a proxy for how suboptimal the default scale is---ranges from $0.09$ (retrieval) to $0.45$ (reasoning), a $5\times$ difference.

\subsection{Benchmark Impact}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/benchmark_impact.pdf}
    \caption{Improvement from learnable multipliers by benchmark. Reasoning benchmarks (red) show $\sim 2\times$ higher improvement than knowledge benchmarks (blue).}
    \label{fig:bench}
\end{figure}

Figure~\ref{fig:bench} confirms the asymmetric impact. Reasoning benchmarks gain $+0.087$ to $+0.103$ while knowledge benchmarks gain $+0.046$ to $+0.057$, a ratio of approximately 2:1.

\subsection{Training Dynamics}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/training_dynamics.pdf}
    \caption{Evolution of multipliers during training by circuit type. Reasoning circuit multipliers diverge fastest from initialization.}
    \label{fig:dynamics}
\end{figure}

Figure~\ref{fig:dynamics} shows that reasoning circuit multipliers diverge from 1.0 earliest and fastest, reaching their optimal values within 50 epochs, while retrieval circuits barely move from initialization.

\subsection{Layer-wise Patterns}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/layer_patterns.pdf}
    \caption{Multiplier values by layer and component, showing increasing deviation in deeper layers.}
    \label{fig:layers}
\end{figure}

Figure~\ref{fig:layers} reveals a clear depth gradient: layers 2--3 have deviations of $0.30$--$0.34$, while layers 0--1 have deviations of $\sim 0.09$. This is consistent with the reasoning-circuit hypothesis, as deeper layers perform more compositional operations.

\section{Discussion}

Our results support the hypothesis that learnable multipliers preferentially enhance reasoning circuits. The mechanism is that reasoning operations---particularly multi-head attention for compositional binding---are more sensitive to the scale of the QK and V projections than retrieval operations. Standard initialization leaves reasoning circuits further from their optimal scale, creating more room for multiplier-based improvement.

This explains the uneven benchmark gains: reasoning benchmarks rely more heavily on these scale-sensitive circuits, while knowledge benchmarks depend primarily on the \emph{content} of weight matrices (stored facts) that multipliers cannot modify.

\section{Conclusion}

We provide quantitative evidence that learnable multipliers exhibit circuit-specific effects, with reasoning circuits showing $5\times$ larger deviations from default scale than retrieval circuits. This directly explains the observed $2\times$ gap between reasoning and knowledge benchmark improvements. Our findings suggest that targeted initialization or per-circuit learning rates could further amplify these gains.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
