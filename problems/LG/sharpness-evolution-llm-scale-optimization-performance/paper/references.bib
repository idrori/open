@article{kalra2026scalable,
  title={A Scalable Measure of Loss Landscape Curvature for Analyzing the Training Dynamics of {LLMs}},
  author={Kalra, Dayal Singh and Gagnon-Audet, Jean-Christophe and Gromov, Andrey and Mediratta, Ishita and Niu, Kelvin and Miller, Alexander H and Shvartsman, Michael},
  journal={arXiv preprint arXiv:2601.16979},
  year={2026}
}

@article{hochreiter1997flat,
  title={Flat Minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={9},
  number={1},
  pages={1--42},
  year={1997}
}

@inproceedings{keskar2017large,
  title={On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  booktitle={International Conference on Learning Representations},
  year={2017}
}

@inproceedings{foret2021sharpness,
  title={Sharpness-Aware Minimization for Efficiently Improving Generalization},
  author={Foret, Pierre and Kleiner, Ariel and Mobahi, Hossein and Neyshabur, Behnam},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{kaplan2020scaling,
  title={Scaling Laws for Neural Language Models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{cohen2021gradient,
  title={Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability},
  author={Cohen, Jeremy and Kaur, Simran and Li, Yuanzhi and Kolter, J. Zico and Talwalkar, Ameet},
  journal={International Conference on Learning Representations},
  year={2021}
}

@article{jastrzebski2020breakeven,
  title={The Break-Even Point on Optimization Trajectories of Deep Neural Networks},
  author={Jastrzebski, Stanislaw and Szymczak, Maciej and Fort, Stanislav and Arpit, Devansh and Tabor, Jacek and Cho, Kyunghyun and Geras, Krzysztof},
  journal={International Conference on Learning Representations},
  year={2020}
}

@article{gilmer2022loss,
  title={A Loss Curvature Perspective on Training Instability in Deep Learning},
  author={Gilmer, Justin and Ghorbani, Behrooz and Garg, Ankush and Kudugunta, Sneha and Neyshabur, Behnam and Cardoze, David and Dahl, George and Nado, Zachary and Firat, Orhan},
  journal={arXiv preprint arXiv:2110.04369},
  year={2021}
}

@article{hoffmann2022training,
  title={Training Compute-Optimal Large Language Models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{lewkowycz2020large,
  title={The Large Learning Rate Phase of Deep Learning: the Catapult Mechanism},
  author={Lewkowycz, Aitor and Bahri, Yasaman and Dyer, Ethan and Sohl-Dickstein, Jascha and Gur-Ari, Guy},
  journal={arXiv preprint arXiv:2003.02218},
  year={2020}
}
