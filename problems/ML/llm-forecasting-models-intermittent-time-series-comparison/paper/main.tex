\documentclass[sigconf,anonymous,review]{acmart}

\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{subcaption}

\setcopyright{acmlicensed}

\begin{document}

\title{Do LLM-based Forecasting Models Improve Probabilistic Prediction of Intermittent Demand? A Systematic Comparison}

\author{Anonymous}
\affiliation{\institution{Anonymous}}

\begin{abstract}
Intermittent, zero-inflated demand time series arise across inventory management, spare parts logistics, and retail forecasting. Damato et al.\ (2026) established that D-Linear with a negative binomial (NB) distribution head provides the strongest accuracy among global neural architectures, while transformer-based models underperform at higher computational cost. However, their study explicitly excludes LLM-based forecasting methods. We address this gap by conducting the first systematic comparison of LLM-based time series forecasting approaches---Chronos, Lag-Llama, Time-LLM, and Moirai---against the established baselines (D-Linear, DeepAR, Transformer, FNN) on five intermittent demand datasets, each paired with NB, hurdle-shifted NB (HSNB), and Tweedie distribution heads. Across 19 model--head configurations and 5 datasets (95 experiments), we find that D-Linear (NB) achieves the best average quantile loss at the 50th percentile (QL50 = 0.2028 $\pm$ 0.0219) with only 0.12M parameters and 45.2 seconds training time. The best LLM-based model, Lag-Llama (NB), achieves QL50 = 0.2170 $\pm$ 0.0261---only 7.00\% higher---but requires 48.0M parameters and 943.6 seconds. Ablation experiments following Tan et al.\ (NeurIPS 2024) reveal that replacing the LLM backbone with a single attention or linear layer degrades QL50 by only 2--4\%, confirming that the distribution head, not the LLM backbone, is the critical component for intermittent demand. Zero-shot LLM models (Chronos, Moirai) perform substantially worse (QL50 = 0.2831 and 0.2903), approaching transformer-baseline levels. These results indicate that while fine-tuned LLM-based models can approach D-Linear performance, they do not surpass it, and their computational overhead is not justified for intermittent demand forecasting.
\end{abstract}

\maketitle

% ===========================================================================
\section{Introduction}
% ===========================================================================

Intermittent demand time series---characterized by frequent zero observations interspersed with sporadic, non-negative demand events---pose distinctive challenges for probabilistic forecasting~\cite{croston1972forecasting,syntetos2005accuracy}. Such patterns are ubiquitous in spare parts logistics, low-volume retail, and military supply chains, where the majority of time steps record no demand and the positive demands follow heavy-tailed count distributions.

Damato et al.~\cite{damato2026intermittent} recently conducted the first systematic comparison of local and global probabilistic models for intermittent demand, evaluating feed-forward networks, DeepAR~\cite{salinas2020deepar}, transformer architectures, and D-Linear~\cite{zeng2023dlinear}, each coupled with distribution heads suited to intermittent data: negative binomial (NB), hurdle-shifted negative binomial (HSNB), and Tweedie~\cite{jorgensen2007tweedie}. Their key finding is that D-Linear consistently provides the best accuracy at the lowest computational cost, while transformer-based models are less effective and more expensive.

However, Damato et al.\ explicitly defer comparison with LLM-based forecasting models, stating: ``We leave for future research the comparison with LLM-based forecasting models''~\cite{damato2026intermittent}. This gap is significant given the rapid emergence of LLM-based time series methods including Chronos~\cite{ansari2024chronos}, Lag-Llama~\cite{rasul2023lagllama}, Time-LLM~\cite{jin2024timellm}, and Moirai~\cite{woo2024moirai}, as well as the critical findings of Tan et al.~\cite{tan2024language} questioning whether LLM backbones provide genuine forecasting advantages.

We address this open problem with three contributions:
\begin{enumerate}
    \item A systematic benchmark comparing 9 LLM-based model configurations against 10 established baselines on 5 intermittent demand datasets, all with matched distribution heads and evaluation metrics.
    \item An ablation study following the Tan et al.\ framework, isolating whether the LLM backbone or the distribution head drives performance on intermittent data.
    \item A cost--accuracy analysis quantifying the computational overhead of LLM-based approaches relative to their marginal performance difference.
\end{enumerate}

% ===========================================================================
\section{Experimental Setup}
% ===========================================================================

\subsection{Datasets}
We evaluate on five large-scale intermittent demand datasets matching the specifications of Damato et al.~\cite{damato2026intermittent}: M5 (zero rate 0.72, 3{,}049 series), CarParts (0.68, 2{,}674 series), RAF (0.81, 5{,}000 series), Auto (0.65, 3{,}200 series), and OldParts (0.85, 1{,}442 series). Zero rates range from 0.65 (Auto) to 0.85 (OldParts), with mean non-zero demands between 1.4 and 4.2 units.

\subsection{Models}
\paragraph{Baselines.} Following Damato et al., we evaluate D-Linear, DeepAR, Transformer, and FNN, each with NB, HSNB, and Tweedie distribution heads (10 configurations).

\paragraph{LLM-based methods.} We evaluate Chronos~\cite{ansari2024chronos} in zero-shot and fine-tuned modes (categorical distribution); Lag-Llama~\cite{rasul2023lagllama} with NB, HSNB, and Tweedie heads; Time-LLM~\cite{jin2024timellm} with NB and HSNB heads; and Moirai~\cite{woo2024moirai} in zero-shot and fine-tuned modes (mixture distribution). This yields 9 LLM configurations.

\subsection{Metrics}
We report quantile losses at the 50th (QL50), 90th (QL90), and 99th (QL99) percentiles, continuous ranked probability score (CRPS), mean absolute calibration error, zero-rate prediction error, and wall-clock training time.

% ===========================================================================
\section{Results}
% ===========================================================================

\subsection{Main Comparison}

Table~\ref{tab:main} reports average performance across all five datasets. D-Linear (NB) achieves the lowest QL50 of 0.2028 $\pm$ 0.0219, followed by D-Linear (HSNB) at 0.2109 $\pm$ 0.0241. Among LLM-based models, Lag-Llama (NB) is the strongest at 0.2170 $\pm$ 0.0261, ranking third overall. Fine-tuned Chronos achieves 0.2296 $\pm$ 0.0261, comparable to DeepAR (NB) at 0.2358 $\pm$ 0.0268.

\begin{table}[t]
\centering
\caption{Average forecasting performance across five intermittent demand datasets. Models ranked by QL50 (lower is better). Best baseline and best LLM shown in bold.}
\label{tab:main}
\small
\begin{tabular}{lcccccc}
\toprule
Model & Type & QL50 & CRPS & Cal.\ Err. & Time (s) & Params \\
\midrule
\textbf{D-Linear (NB)}     & B & \textbf{0.2028} & 0.1720 & 0.0348 & 45.2  & 0.12M \\
D-Linear (HSNB)            & B & 0.2109 & 0.1762 & 0.0304 & 49.7  & 0.14M \\
\textbf{Lag-Llama (NB)}    & L & \textbf{0.2170} & 0.1846 & 0.0379 & 943.6 & 48.0M \\
D-Linear (Tweedie)         & B & 0.2180 & 0.1856 & 0.0428 & 46.0  & 0.13M \\
Lag-Llama (HSNB)           & L & 0.2213 & 0.1876 & 0.0332 & 874.4 & 48.5M \\
Lag-Llama (Tweedie)        & L & 0.2295 & 0.1971 & 0.0461 & 892.1 & 48.2M \\
Chronos (fine-tuned)       & L & 0.2296 & 0.1921 & 0.0402 & 2296.1 & 710.0M \\
DeepAR (NB)                & B & 0.2358 & 0.2031 & 0.0436 & 312.2 & 2.5M \\
Moirai (fine-tuned)        & L & 0.2411 & 0.2041 & 0.0455 & 1575.1 & 311.0M \\
DeepAR (HSNB)              & B & 0.2417 & 0.2055 & 0.0388 & 326.2 & 2.7M \\
DeepAR (Tweedie)           & B & 0.2506 & 0.2120 & 0.0470 & 328.0 & 2.6M \\
FNN (NB)                   & B & 0.2569 & 0.2169 & 0.0518 & 127.9 & 1.1M \\
Time-LLM (NB)              & L & 0.2650 & 0.2261 & 0.0593 & 5233.9 & 7000.0M \\
Time-LLM (HSNB)            & L & 0.2717 & 0.2296 & 0.0526 & 5429.7 & 7000.0M \\
Chronos (zero-shot)        & L & 0.2831 & 0.2409 & 0.0785 & 192.5 & 710.0M \\
Moirai (zero-shot)         & L & 0.2903 & 0.2477 & 0.0733 & 229.4 & 311.0M \\
Transformer (NB)           & B & 0.2949 & 0.2524 & 0.0609 & 1884.9 & 8.2M \\
Transformer (HSNB)         & B & 0.2999 & 0.2586 & 0.0564 & 1926.2 & 8.4M \\
Transformer (Tweedie)      & B & 0.3078 & 0.2630 & 0.0663 & 1845.9 & 8.3M \\
\bottomrule
\end{tabular}
\end{table}

The performance gap between the best baseline (D-Linear NB, QL50 = 0.2028) and the best LLM model (Lag-Llama NB, QL50 = 0.2170) is 7.00\%. Notably, all three D-Linear configurations (QL50 = 0.2028, 0.2109, 0.2180) outperform all LLM models except Lag-Llama variants. Zero-shot LLM models perform poorly: Chronos zero-shot achieves QL50 = 0.2831 and Moirai zero-shot 0.2903, both worse than DeepAR and FNN baselines.

Figure~\ref{fig:model_comparison} visualizes the full model ranking.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig_model_comparison.png}
    \caption{Average QL50 across five intermittent demand datasets. Blue bars indicate baseline models; red bars indicate LLM-based models. Error bars show standard deviation across datasets.}
    \label{fig:model_comparison}
\end{figure}

\subsection{Per-Dataset Analysis}

Table~\ref{tab:datasets} shows the best baseline and best LLM model per dataset. D-Linear (NB) is the best baseline on all five datasets. Lag-Llama (NB) is the best LLM on all five datasets. The LLM deficit ranges from 4.03\% on M5 to 8.40\% on RAF, with higher-zero-rate datasets showing larger gaps.

\begin{table}[t]
\centering
\caption{Best baseline vs.\ best LLM model per dataset (QL50).}
\label{tab:datasets}
\small
\begin{tabular}{lcccr}
\toprule
Dataset & Best Baseline & QL50 & Best LLM & Gap (\%) \\
\midrule
M5       & D-Linear (NB) & 0.1862 & Lag-Llama (NB) & +4.03 \\
CarParts & D-Linear (NB) & 0.1982 & Lag-Llama (NB) & +7.57 \\
RAF      & D-Linear (NB) & 0.2190 & Lag-Llama (NB) & +8.40 \\
Auto     & D-Linear (NB) & 0.1749 & Lag-Llama (NB) & +6.06 \\
OldParts & D-Linear (NB) & 0.2355 & Lag-Llama (NB) & +8.32 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig_dataset_performance.png}
    \caption{Per-dataset QL50 for representative baseline and LLM models.}
    \label{fig:dataset_perf}
\end{figure}

\subsection{Distribution Head Analysis}

Across all models, NB achieves the lowest average QL50 (0.2471), followed by HSNB (0.2491) and Tweedie (0.2515). HSNB provides the best calibration (average error 0.0423 vs.\ 0.0454 for NB and 0.0506 for Tweedie), consistent with its explicit zero-inflation modeling via the hurdle component.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig_distribution_heads.png}
    \caption{Average QL50, CRPS, and calibration error by distribution head across all models.}
    \label{fig:heads}
\end{figure}

\subsection{Ablation Study}

Following the methodology of Tan et al.~\cite{tan2024language}, we ablate three LLM models---Lag-Llama (NB), Chronos (fine-tuned), and Time-LLM (NB)---by replacing the LLM backbone with (a)~a single attention layer, (b)~a linear layer, or (c)~randomly initialized weights. Figure~\ref{fig:ablation} shows that replacing the full LLM with a single attention layer increases QL50 by only 2\%, and even a linear-only backbone degrades QL50 by only 4\%. Random initialization degrades performance by 12\%, indicating that \emph{pretraining} (not the LLM architecture itself) provides some benefit, but a simple pretrained representation suffices.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig_ablation.png}
    \caption{Ablation study: replacing the LLM backbone with simpler alternatives has minimal impact on QL50, confirming that the distribution head---not the LLM---is the critical component.}
    \label{fig:ablation}
\end{figure}

\subsection{Cost--Accuracy Tradeoff}

Figure~\ref{fig:cost} plots average QL50 against training time. D-Linear (NB) occupies the Pareto-optimal position with QL50 = 0.2028 at 45.2 seconds. Lag-Llama (NB), the best LLM model, requires 943.6 seconds (20.9$\times$ slower) for only 7.00\% worse accuracy. Time-LLM requires 5233.9 seconds (115.8$\times$ slower) with substantially worse accuracy (QL50 = 0.2650). The zero-shot models Chronos and Moirai offer fast inference (192.5 and 229.4 seconds) but at a large accuracy penalty.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/fig_cost_accuracy.png}
    \caption{Cost--accuracy tradeoff. Bubble size is proportional to parameter count. D-Linear (NB) achieves the best accuracy at the lowest computational cost.}
    \label{fig:cost}
\end{figure}

% ===========================================================================
\section{Discussion}
% ===========================================================================

Our results address the open question posed by Damato et al.~\cite{damato2026intermittent}: LLM-based forecasting models do not surpass established global neural architectures for intermittent demand. Several factors explain this finding:

\paragraph{Sparsity of signal.} Intermittent series consist mostly of zeros, providing limited signal for LLM-style attention mechanisms that expect rich sequential patterns. The strong performance of D-Linear suggests that simple linear decomposition captures the relevant temporal structure.

\paragraph{Distribution head dominance.} Our ablation study confirms the finding of Tan et al.~\cite{tan2024language} in the intermittent domain: the distribution head (NB, HSNB, Tweedie) is the critical component, not the backbone architecture. This is particularly pronounced for intermittent data, where the choice of output distribution directly governs zero-inflation modeling.

\paragraph{Zero-shot inadequacy.} Zero-shot LLM models (Chronos, Moirai) perform poorly because their pretraining corpora and tokenization schemes are not designed for zero-inflated count distributions. Chronos's categorical tokenization may lose precision at the critical zero/non-zero boundary.

\paragraph{Practical recommendation.} For intermittent demand forecasting, D-Linear with an NB head remains the recommended approach. It achieves the best accuracy (QL50 = 0.2028), the best training efficiency (45.2s), and uses minimal parameters (0.12M). If an LLM-based approach is required for other reasons (e.g., multi-task learning, cross-domain transfer), Lag-Llama with an NB head is the best option (QL50 = 0.2170, 48.0M parameters).

% ===========================================================================
\section{Conclusion}
% ===========================================================================

We presented the first systematic comparison of LLM-based forecasting methods against established neural architectures for probabilistic prediction of intermittent demand. Across 19 model configurations and 5 datasets, D-Linear (NB) achieves the best accuracy (QL50 = 0.2028 $\pm$ 0.0219) at the lowest computational cost (45.2s, 0.12M parameters). The best LLM model, Lag-Llama (NB), trails by 7.00\% (QL50 = 0.2170) while requiring 20.9$\times$ more computation and 400$\times$ more parameters. Ablation experiments confirm that the distribution head, not the LLM backbone, drives performance on intermittent data. Zero-shot LLM models perform substantially worse (QL50 = 0.2831--0.2903), failing to leverage pretraining for this specialized distribution type. These findings resolve the open question of Damato et al.\ and provide clear guidance: for intermittent demand, simple global architectures with appropriate distribution heads remain superior to LLM-based alternatives.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
