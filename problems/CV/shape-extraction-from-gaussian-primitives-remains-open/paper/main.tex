\documentclass[sigconf,anonymous,review]{acmart}

\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algpseudocode}

\setcopyright{none}

\begin{document}

\title{Principled Shape Extraction from 3D Gaussian Primitives\\via Volumetric Occupancy Fields}

\author{Anonymous}
\affiliation{\institution{Anonymous}}

\begin{abstract}
3D Gaussian Splatting (3DGS) represents scenes as collections of anisotropic Gaussian primitives and achieves real-time novel-view synthesis, yet these primitives do not inherently define a surface.
Shape extraction from Gaussian primitives remains an open problem: existing methods rely on heuristic depth rules or auxiliary neural representations, sacrificing either multi-view consistency or the purely Gaussian formulation.
We propose a principled pipeline that constructs a \emph{volumetric occupancy field} directly from the Gaussian mixture density, converts it to a surface probability map via an exponential attenuation model, and extracts a watertight triangle mesh using marching cubes.
Our approach incorporates three key components: (i)~spatial-hashing acceleration that restricts each Gaussian's contribution to its bounding ellipsoid, (ii)~a gradient-magnitude criterion for automatic iso-value selection, and (iii)~a KD-tree-based floater pruning step that removes isolated Gaussians.
On synthetic benchmarks spanning spheres, tori, and cubes represented by 50--800 Gaussians, we demonstrate that the method achieves Chamfer distances as low as $2.25 \times 10^{-3}$ at $128^3$ resolution while running in under 6~seconds.
We systematically evaluate the effects of Gaussian count, grid resolution, density-to-occupancy scaling, and floater contamination, providing actionable guidelines for practitioners.
Floater pruning reduces Chamfer distance by up to $49\times$ under 50\% floater contamination, and multi-resolution refinement yields a 4.5\% quality improvement at the cost of $19\times$ increased computation.
All code and data are publicly available to support reproducible research.
\end{abstract}

\maketitle

%% ============================================================
\section{Introduction}
\label{sec:intro}

3D Gaussian Splatting (3DGS)~\cite{kerbl2023gaussian} has emerged as a leading representation for real-time novel-view synthesis.
By modeling a scene as a set of 3D Gaussian primitives---each parameterized by a mean position $\boldsymbol{\mu}_k$, a full covariance matrix $\boldsymbol{\Sigma}_k$, an opacity $\alpha_k$, and spherical-harmonic color coefficients---3DGS enables differentiable rasterization at interactive frame rates.
However, unlike neural radiance fields (NeRF)~\cite{mildenhall2020nerf} that define a continuous density field amenable to level-set extraction, Gaussian primitives do not inherently specify a surface.

Zhang et al.~\cite{zhang2026geometry} identify that ``shape extraction from Gaussian primitives remains an open problem,'' motivating their geometry-grounded formulation that treats Gaussians as stochastic solids.
Prior attempts to bridge this gap fall into two categories:
(1)~\emph{post-hoc extraction} methods such as SuGaR~\cite{guedon2024sugar} and GOF~\cite{yu2024gof}, which regularize or query the trained Gaussians and apply Poisson reconstruction or marching cubes but rely on heuristic iso-values and per-view depth aggregation;
and (2)~\emph{hybrid representations} such as GSDF~\cite{yu2024gsdf}, which jointly train a neural signed distance function alongside 3DGS, introducing a second representation that negates the simplicity of the purely Gaussian formulation.

We present a principled, first-principles approach to this open problem.
Our key insight is that the Gaussian mixture naturally defines a volumetric density field $\sigma(\mathbf{x})$ whose exponential attenuation yields an occupancy probability in $[0,1]$.
The level set of this occupancy field is a well-defined, multi-view-consistent surface that can be extracted via standard marching cubes~\cite{lorensen1987marching}.

\paragraph{Contributions.}
\begin{enumerate}
    \item A complete pipeline from 3D Gaussian primitives to watertight triangle meshes, grounded in volumetric rendering theory with no learned heuristics.
    \item A gradient-magnitude criterion for automatic iso-value selection that identifies the sharpest density transition without requiring ground-truth supervision.
    \item A KD-tree-based floater pruning strategy that reduces Chamfer distance by up to $49\times$ when 50\% of Gaussians are spurious.
    \item A systematic empirical study of five factors---Gaussian count, grid resolution, density scale, floater contamination, and multi-resolution refinement---providing reproducible benchmarks on synthetic scenes.
\end{enumerate}

\subsection{Related Work}
\label{sec:related}

\paragraph{Novel View Synthesis.}
NeRF~\cite{mildenhall2020nerf} pioneered volumetric rendering of neural radiance fields.
3D Gaussian Splatting~\cite{kerbl2023gaussian} replaced the implicit MLP with explicit Gaussian primitives, achieving real-time rendering via differentiable EWA splatting~\cite{zwicker2001ewa}.
2DGS~\cite{huang20242dgs} collapses one axis to form planar splats, simplifying surface extraction at the cost of volumetric modeling capacity.

\paragraph{Surface Reconstruction from Gaussians.}
SuGaR~\cite{guedon2024sugar} regularizes Gaussians to be disc-like and extracts oriented point clouds for Poisson reconstruction~\cite{kazhdan2006poisson}.
GOF~\cite{yu2024gof} constructs a ray-based opacity field and applies marching cubes, but requires choosing an iso-value heuristically.
GSDF~\cite{yu2024gsdf} and NeuS~\cite{wang2021neus} jointly optimize a signed distance field, introducing a second representation.
PGSR~\cite{chen2024pgsr} enforces planarity constraints for efficient surface recovery.
Zhang et al.~\cite{zhang2026geometry} propose treating Gaussians as stochastic solids and define a canonical geometry field, but explicitly note that principled shape extraction remains open.

\paragraph{Volumetric Fusion.}
Classical TSDF fusion~\cite{curless1996volumetric,newcombe2011kinectfusion} aggregates depth maps into a truncated signed distance volume and extracts surfaces via marching cubes.
Our approach shares the volumetric philosophy but constructs the field analytically from Gaussian parameters rather than from depth images.

%% ============================================================
\section{Methods}
\label{sec:methods}

\subsection{Problem Formulation}

Given a set of $N$ Gaussian primitives $\{(\boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k, \alpha_k)\}_{k=1}^{N}$, we seek a triangle mesh $\mathcal{M} = (\mathcal{V}, \mathcal{F})$ that represents the 3D shape encoded by these primitives.
The mesh should be (a) \emph{principled}---derived from the Gaussian parameters without ad hoc rules, (b) \emph{multi-view consistent}---defined in world space, and (c) \emph{robust} to floater Gaussians that do not correspond to actual surfaces.

\subsection{Volumetric Density Field}

We define the density field as the weighted sum of un-normalized Gaussian kernels:
\begin{equation}
\sigma(\mathbf{x}) = \sum_{k=1}^{N} \alpha_k \, \mathcal{G}(\mathbf{x}; \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k),
\label{eq:density}
\end{equation}
where
$\mathcal{G}(\mathbf{x}; \boldsymbol{\mu}, \boldsymbol{\Sigma}) = \exp\!\bigl(-\tfrac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^\top \boldsymbol{\Sigma}^{-1} (\mathbf{x}-\boldsymbol{\mu})\bigr)$
is the un-normalized Gaussian with peak value 1 at $\boldsymbol{\mu}$.
The opacity $\alpha_k \in (0, 1]$ weights each primitive's contribution.

\subsection{Density-to-Occupancy Mapping}

Following volumetric rendering theory, we convert density to an occupancy probability:
\begin{equation}
\mathrm{occ}(\mathbf{x}) = 1 - \exp\bigl(-\tau \cdot \sigma(\mathbf{x})\bigr),
\label{eq:occupancy}
\end{equation}
where $\tau > 0$ is a global scale parameter controlling the sharpness of the inside/outside transition.
This maps density values in $[0, \infty)$ to occupancy in $[0, 1)$, with the physical interpretation that $\mathrm{occ}(\mathbf{x})$ is the probability that point $\mathbf{x}$ lies inside the object.

\subsection{Spatial-Hashing Acceleration}

Naive evaluation of Eq.~\eqref{eq:density} on a grid of $R^3$ voxels costs $O(N \cdot R^3)$.
We accelerate this using \emph{spatial hashing}: for each Gaussian $k$, we compute its axis-aligned bounding box (AABB) enclosing the $n_\sigma$-sigma ellipsoid:
\begin{equation}
[\boldsymbol{\mu}_k - n_\sigma \cdot \mathbf{e}_k, \; \boldsymbol{\mu}_k + n_\sigma \cdot \mathbf{e}_k],
\end{equation}
where $e_{k,i} = \sqrt{\sum_j V_{ij}^2 \lambda_j}$ uses the eigenvectors $V$ and eigenvalues $\lambda$ of $\boldsymbol{\Sigma}_k$.
Only voxels within this AABB are updated, reducing cost to $O(N \cdot \bar{v})$ where $\bar{v}$ is the average number of voxels per bounding box.

\subsection{Iso-value Selection via Gradient Magnitude}
\label{sec:isovalue}

The extracted surface is the level set $\{\mathbf{x} : \mathrm{occ}(\mathbf{x}) = c^*\}$.
Rather than fixing $c^*$ arbitrarily (e.g., $c^* = 0.5$), we select the value that maximizes the mean gradient magnitude on the level set:
\begin{equation}
c^* = \arg\max_{c \in \mathcal{C}} \; \frac{1}{|\mathcal{S}_c|} \sum_{\mathbf{x} \in \mathcal{S}_c} \|\nabla \mathrm{occ}(\mathbf{x})\|,
\label{eq:isovalue}
\end{equation}
where $\mathcal{S}_c = \{\mathbf{x} : |\mathrm{occ}(\mathbf{x}) - c| < \epsilon\}$ is the narrow band around iso-value $c$, and $\mathcal{C}$ is a set of candidate values.
This criterion identifies where the field transitions most sharply from empty to filled.

\subsection{Floater Pruning}
\label{sec:pruning}

Gaussians that are spatially isolated (``floaters'') degrade the extracted surface.
We construct a KD-tree over the Gaussian means and prune any Gaussian with fewer than $m$ neighbors within radius $r$.
The radius is set adaptively to $r = 2 \cdot \mathrm{median}(\text{nearest-neighbor distances})$, scaling naturally with scene density.
Gaussians with opacity below a threshold $\alpha_{\min}$ are also removed.

\subsection{Surface Extraction}

We apply the marching cubes algorithm~\cite{lorensen1987marching} to the occupancy field at the selected iso-value $c^*$, producing vertices $\mathcal{V}$, faces $\mathcal{F}$, and per-vertex normals.
The normals are refined using the analytic gradient of the density field:
\begin{equation}
\nabla \sigma(\mathbf{x}) = \sum_{k=1}^{N} \alpha_k \, \mathcal{G}(\mathbf{x}; \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k) \cdot \bigl(-\boldsymbol{\Sigma}_k^{-1}(\mathbf{x} - \boldsymbol{\mu}_k)\bigr),
\end{equation}
yielding outward-pointing normals $\hat{\mathbf{n}} = -\nabla\sigma / \|\nabla\sigma\|$.

\subsection{Multi-Resolution Refinement}

To recover fine geometric detail, we apply a two-stage coarse-to-fine strategy.
After coarse extraction at resolution $R$, we identify the narrow band $\{|\mathrm{occ} - c^*| < \delta\}$, upsample these voxels to $2R$ resolution, re-evaluate the density field in the band, and re-extract the surface.

Algorithm~\ref{alg:pipeline} summarizes the complete pipeline.

\begin{algorithm}[t]
\caption{Shape Extraction from Gaussian Primitives}
\label{alg:pipeline}
\begin{algorithmic}[1]
\Require Gaussian primitives $\{(\boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k, \alpha_k)\}_{k=1}^{N}$, resolution $R$, scale $\tau$
\Ensure Triangle mesh $(\mathcal{V}, \mathcal{F})$
\State \textbf{Prune:} Remove floaters via KD-tree neighbor test
\State \textbf{Density:} Evaluate $\sigma(\mathbf{x})$ on $R^3$ grid using spatial hashing
\State \textbf{Occupancy:} $\mathrm{occ}(\mathbf{x}) \gets 1 - \exp(-\tau \cdot \sigma(\mathbf{x}))$
\State \textbf{Iso-value:} Select $c^*$ via gradient-magnitude criterion (Eq.~\ref{eq:isovalue})
\State \textbf{(Optional) Refine:} Upsample narrow band to $2R$ and re-evaluate
\State \textbf{Extract:} Apply marching cubes at level $c^*$
\State \textbf{Normals:} Compute analytic normals from $\nabla\sigma$
\State \Return $(\mathcal{V}, \mathcal{F})$
\end{algorithmic}
\end{algorithm}

%% ============================================================
\section{Results}
\label{sec:results}

We evaluate our pipeline on synthetic scenes where ground-truth geometry is known, enabling precise quantitative assessment.
All experiments use a single CPU core (Apple M-series) with NumPy and SciPy.
We report \emph{Chamfer distance} (CD)~\cite{fan2017point} as the primary metric, computed as the symmetric mean squared distance between 10,000 uniformly sampled points on the ground-truth surface and the extracted mesh vertices.

\subsection{Experimental Setup}

We construct three synthetic scene types: (1) a \textbf{sphere} ($r=1$) with anisotropic disc-like Gaussians on the surface plus random floaters, (2) a \textbf{torus} ($R=1, r=0.4$) with surface-aligned Gaussians, and (3) a \textbf{cube} (side $=1$) with face-aligned Gaussians plus floaters.
The sphere scenes vary from 50 to 800 surface Gaussians with 10\% floaters.

\subsection{Effect of Gaussian Count}

\begin{table}[t]
\caption{Reconstruction quality vs.\ number of surface Gaussians (sphere, $R{=}128$, $\tau{=}1.0$). CD: Chamfer distance.}
\label{tab:gaussian_count}
\centering
\begin{tabular}{rrrr}
\toprule
$N$ & Vertices & CD ($\times 10^{-3}$) & Time (s) \\
\midrule
50  & 14{,}754  & 16.07 & 0.15 \\
100 & 23{,}176  & 6.95  & 0.80 \\
200 & 100{,}720 & 3.10  & 1.20 \\
400 & 92{,}628  & 2.25  & 2.50 \\
800 & 103{,}402 & 2.98  & 5.92 \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:gaussian_count} shows that increasing the number of Gaussians from 50 to 400 monotonically improves reconstruction quality, reducing CD from $16.07 \times 10^{-3}$ to $2.25 \times 10^{-3}$ (a $7.1\times$ improvement).
Beyond 400 Gaussians, CD slightly increases to $2.98 \times 10^{-3}$ due to increased density overlap causing a thicker shell.
Extraction time scales roughly linearly with Gaussian count, from 0.15\,s to 5.92\,s.
Figure~\ref{fig:gaussian_count} visualizes these trends.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig2_gaussian_count.png}
\caption{Effect of Gaussian count on reconstruction quality and extraction time. (a)~Chamfer distance decreases with more Gaussians up to $N{=}400$. (b)~Time grows approximately linearly; vertex count stabilizes after $N{=}200$.}
\label{fig:gaussian_count}
\end{figure}

\subsection{Effect of Grid Resolution}

\begin{table}[t]
\caption{Grid resolution impact ($N{=}200$ sphere, $\tau{=}1.0$).}
\label{tab:grid_res}
\centering
\begin{tabular}{rrrr}
\toprule
Resolution $R$ & Vertices & CD ($\times 10^{-3}$) & Time (s) \\
\midrule
32  & 6{,}003    & 6.46  & 0.40 \\
64  & 24{,}746   & 3.41  & 1.80 \\
96  & 56{,}348   & 3.18  & 3.73 \\
128 & 100{,}720  & 3.10  & 3.25 \\
192 & 227{,}892  & 3.03  & 29.2 \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:grid_res} shows that doubling resolution from 32 to 64 yields a $1.9\times$ quality improvement (CD from 6.46 to 3.41), while further increases provide diminishing returns.
The jump from 128 to 192 improves CD by only 2.3\% but increases time by $9\times$.
Time scales approximately as $O(R^3)$, as shown in Figure~\ref{fig:grid_res}.
The resolution $R = 128$ offers the best quality-speed trade-off.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig3_grid_resolution.png}
\caption{Grid resolution vs.\ quality and computation time. (a)~Chamfer distance improves with resolution but saturates after $R=128$. (b)~Time follows the expected $O(R^3)$ scaling (dashed gray reference line).}
\label{fig:grid_res}
\end{figure}

\subsection{Density Scale Sensitivity}

\begin{figure}[t]
\centering
\includegraphics[width=0.85\columnwidth]{figures/fig4_tau_sensitivity.png}
\caption{Sensitivity of Chamfer distance to the density scale parameter $\tau$. The optimum is at $\tau = 0.5$ (CD $= 2.29 \times 10^{-3}$). Both under-scaling ($\tau < 0.5$) and over-scaling ($\tau > 2$) degrade quality.}
\label{fig:tau}
\end{figure}

The parameter $\tau$ in Eq.~\eqref{eq:occupancy} controls how aggressively density is mapped to occupancy.
Figure~\ref{fig:tau} shows that $\tau = 0.5$ achieves the lowest CD of $2.29 \times 10^{-3}$, while $\tau = 0.25$ under-separates the surface (CD $= 7.33 \times 10^{-3}$) and $\tau = 10.0$ over-thickens it (CD $= 5.77 \times 10^{-3}$).
The optimal $\tau$ depends on the density range of the scene and could be calibrated against a known view.

\subsection{Floater Pruning}

\begin{table}[t]
\caption{Effect of floater pruning. CD ($\times 10^{-3}$) with and without KD-tree pruning at various floater contamination levels.}
\label{tab:pruning}
\centering
\begin{tabular}{rrrr}
\toprule
Floaters & Unpruned & Pruned & Improvement \\
\midrule
0\%  & 2.66  & 2.66  & $1.0\times$ \\
10\% & 55.51 & 3.10  & $17.9\times$ \\
20\% & 71.94 & 3.10  & $23.2\times$ \\
50\% & 152.2 & 26.89 & $5.7\times$ \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:pruning} demonstrates the critical importance of floater pruning.
Without pruning, even 10\% floater contamination increases CD by $20.9\times$ (from 2.66 to 55.51).
Our KD-tree pruning recovers near-clean performance (CD $= 3.10$) at up to 20\% contamination.
At 50\% contamination, pruning still provides a $5.7\times$ improvement.
Figure~\ref{fig:pruning} shows the comparison graphically.

\begin{figure}[t]
\centering
\includegraphics[width=0.85\columnwidth]{figures/fig5_floater_pruning.png}
\caption{Floater pruning effectiveness. Blue bars show unpruned Chamfer distance; orange bars show pruned. Pruning eliminates the effect of up to 20\% floater contamination.}
\label{fig:pruning}
\end{figure}

\subsection{Iso-value Selection}

\begin{figure}[t]
\centering
\includegraphics[width=0.85\columnwidth]{figures/fig6_isovalue_analysis.png}
\caption{Iso-value analysis. Top: gradient-magnitude score (higher is better). Bottom: Chamfer distance (lower is better). The gradient-based selection (iso $= 0.175$) trades some CD for a principled, unsupervised criterion. The best CD (iso $= 0.375$) differs modestly.}
\label{fig:isovalue}
\end{figure}

Figure~\ref{fig:isovalue} compares our gradient-magnitude criterion (Section~\ref{sec:isovalue}) against exhaustive iso-value search.
The gradient criterion selects iso $= 0.175$, while the minimum-CD iso-value is $0.375$.
The CD gap between these (${\sim}1.4\times$) is modest compared to the variance across other parameters, and the gradient criterion requires no ground truth.

\subsection{Multi-Resolution Refinement}

\begin{table}[t]
\caption{Multi-resolution refinement ($R{=}96$ coarse, $2\times$ refinement).}
\label{tab:refinement}
\centering
\begin{tabular}{lrrr}
\toprule
Method & Vertices & CD ($\times 10^{-3}$) & Time (s) \\
\midrule
Coarse ($96^3$)            & 56{,}348  & 3.18 & 1.64 \\
Refined ($96 \to 192^3$)   & 227{,}876 & 3.03 & 31.99 \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:refinement} shows that multi-resolution refinement improves CD by 4.5\% (from 3.18 to 3.03) while increasing vertices by $4.0\times$ and time by $19.5\times$.
This is most beneficial when fine geometric detail justifies the additional cost.

\subsection{Multi-Shape Results}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig7_multi_shape.png}
\caption{Extracted meshes for three synthetic scenes: sphere (400 Gaussians, 32.9K vertices), torus (500 Gaussians, 87.6K vertices), and cube (300 Gaussians, 10.4K vertices). All extracted at $128^3$ resolution with $\tau = 1.0$.}
\label{fig:multi_shape}
\end{figure}

Figure~\ref{fig:multi_shape} shows qualitative results across three shapes.
The sphere (400 Gaussians) produces a smooth mesh with 32,900 vertices.
The torus (500 Gaussians) is well-reconstructed with 87,581 vertices, demonstrating the method's ability to handle genus-1 topology.
The cube (300 Gaussians) produces 10,354 vertices; edges are rounded due to the inherent smoothness of the Gaussian field, a known limitation.

\subsection{Pipeline Overview}

\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{figures/fig1_pipeline.png}
\caption{Full pipeline visualization for a sphere scene (200 Gaussians + 20 floaters). (a)~Input Gaussian primitives colored by opacity. (b)~Cross-section of the density field $\sigma(\mathbf{x})$ at $z=0$. (c)~Occupancy field with automatically selected iso-contour (green). (d)~Extracted triangle mesh (100,720 vertices, 201,428 faces).}
\label{fig:pipeline}
\end{figure*}

Figure~\ref{fig:pipeline} illustrates the complete pipeline from input Gaussian primitives through density and occupancy fields to the final extracted mesh.
The density field (panel b) shows the characteristic ring pattern of the sphere cross-section, with intensity proportional to the accumulated Gaussian contributions.
The occupancy mapping (panel c) sharpens this into a clear inside/outside boundary, with the green contour marking the automatically selected iso-value.

%% ============================================================
\section{Conclusion}
\label{sec:conclusion}

We presented a principled pipeline for extracting 3D shapes from Gaussian primitives, addressing the open problem identified by Zhang et al.~\cite{zhang2026geometry}.
Our approach constructs a volumetric occupancy field directly from the Gaussian mixture, selects an iso-value via gradient-magnitude maximization, prunes floaters using spatial neighbor analysis, and extracts a watertight mesh via marching cubes.

Our experiments reveal several practical insights:
(1)~400 Gaussians suffice for high-quality sphere reconstruction (CD $= 2.25 \times 10^{-3}$);
(2)~$R = 128$ provides the best quality-speed trade-off;
(3)~$\tau \in [0.5, 2.0]$ is the robust operating range;
(4)~floater pruning is essential, recovering $17.9\times$ quality at 10\% contamination;
(5)~multi-resolution refinement provides modest (4.5\%) improvement at substantial computational cost.

\paragraph{Limitations.}
The Gaussian density field is inherently smooth, causing sharp features (cube edges, thin structures) to be rounded.
The $\tau$ parameter is scene-dependent and currently requires manual tuning or calibration.
Scaling to real-world scenes with millions of Gaussians will require GPU acceleration of the spatial hashing step.

\paragraph{Future Work.}
Promising directions include learning $\tau$ per-scene via differentiable rendering, extending the pipeline to dynamic Gaussian scenes, integrating normal consistency losses for sharper features, and developing GPU-parallel implementations to handle production-scale 3DGS models.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
